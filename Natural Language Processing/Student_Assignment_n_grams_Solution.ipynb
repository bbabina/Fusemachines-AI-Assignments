{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRxGRfy56o-B"
      },
      "source": [
        "# Sentence Generation with n-grams\n",
        "## Learning Objective\n",
        "Here in this assignment, you will create a bigram model from the Brown corpus. You will use Laplace smoothing for bigrams and you will evaluate the perplexity of the model.\n",
        "\n",
        "In the last portion of the assignment, you will generate sentences from the bigram model.\n",
        "\n",
        "<b><div style=\"text-align: right\">[TOTAL POINTS: 10]</div></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys4IxPkX6o-D"
      },
      "source": [
        "## Assignment Overview\n",
        "\n",
        "In this assignment you will be assigned to do the following tasks.\n",
        "\n",
        "* Preprocessig Dataset (lowercasing, removing punctuations, adding start and end tokens)\n",
        "* Adding unknown tokens\n",
        "* Creating n-grams and their corresponding counts\n",
        "* Creating Laplace Smoothing n-gram model\n",
        "* Calculating Perplexity of the model\n",
        "* Bonus (Sentence Generation with the model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKuqgEJn6o-E"
      },
      "source": [
        "## Dataset Description:\n",
        "\n",
        "**Brown Corpus**\n",
        "\n",
        "The Brown Corpus is an electronic collection of text samples of American English in a varied genres. It was compiled by W. N. Francis and H. Kucera, Brown University.\n",
        "\n",
        "The corpus contains one million words of American English sampled from 15 different text categories. This corpus consists of 500 texts from different genres, each consisting of over 2000 words. The different text categories are as follows:\n",
        "\n",
        "    1. Report (44 texts)\n",
        "    2. Editorial (27 texts)\n",
        "    3. Reviews (17 texts)\n",
        "    4. Religion (17 texts)\n",
        "    5. Skill and Hobbies (36 texts)\n",
        "    6. Popular Lore (48 texts)\n",
        "    7. Belles-Lettres (75 texts)\n",
        "    8. Government (30 texts)\n",
        "    9. Learned (80 texts)\n",
        "    10. Fiction: General (29 texts)\n",
        "    11. Fiction: Mystery (24 texts)\n",
        "    12. Fiction: Science (6 texts)\n",
        "    13. Fiction: Adventure (29 texts)\n",
        "    14. Fiction: Romance (29 texts)\n",
        "    15. Humor (9 texts)\n",
        "\n",
        "*Source:* https://www1.essex.ac.uk/linguistics/external/clmt/w3c/corpus_ling/content/corpora/list/private/brown/brown.html \\\n",
        "*Author: W.N. Francis and H. Kucera, Brown University, Providence, RI*\n",
        "\n",
        "The Brown corpus is available in [NLTK corpora](http://www.nltk.org/nltk_data/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSAYyaEyG40M"
      },
      "outputs": [],
      "source": [
        "!pip install -q nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q15XKfic6o-F",
        "outputId": "6f1ae9c9-c4fb-4274-ba05-9e60dd4dfb3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('brown')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0zPxVuD6o-G",
        "outputId": "56c53726-296b-408d-e90e-4e1ab788c8be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['adventure',\n",
              " 'belles_lettres',\n",
              " 'editorial',\n",
              " 'fiction',\n",
              " 'government',\n",
              " 'hobbies',\n",
              " 'humor',\n",
              " 'learned',\n",
              " 'lore',\n",
              " 'mystery',\n",
              " 'news',\n",
              " 'religion',\n",
              " 'reviews',\n",
              " 'romance',\n",
              " 'science_fiction']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from nltk.corpus import brown\n",
        "categories = brown.categories()\n",
        "categories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li7VUUaC6o-H"
      },
      "source": [
        "In the train set, you will use sentences from categories `'adventure', 'editorial', 'fiction', 'hobbies', 'humor', 'lore', 'mystery' 'reviews'`.\n",
        "\n",
        "And for the test set, you will use sentences from categories `'romance'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcTuKI796o-H",
        "outputId": "d6add6aa-08c9-4c71-9041-c39c69f99701",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data: \n",
            "[['Assembly', 'session', 'brought', 'much', 'good'], ['The', 'General', 'Assembly', ',', 'which', 'adjourns', 'today', ',', 'has', 'performed', 'in', 'an', 'atmosphere', 'of', 'crisis', 'and', 'struggle', 'from', 'the', 'day', 'it', 'convened', '.'], ['It', 'was', 'faced', 'immediately', 'with', 'a', 'showdown', 'on', 'the', 'schools', ',', 'an', 'issue', 'which', 'was', 'met', 'squarely', 'in', 'conjunction', 'with', 'the', 'governor', 'with', 'a', 'decision', 'not', 'to', 'risk', 'abandoning', 'public', 'education', '.'], ['There', 'followed', 'the', 'historic', 'appropriations', 'and', 'budget', 'fight', ',', 'in', 'which', 'the', 'General', 'Assembly', 'decided', 'to', 'tackle', 'executive', 'powers', '.'], ['The', 'final', 'decision', 'went', 'to', 'the', 'executive', 'but', 'a', 'way', 'has', 'been', 'opened', 'for', 'strengthening', 'budgeting', 'procedures', 'and', 'to', 'provide', 'legislators', 'information', 'they', 'need', '.'], ['Long-range', 'planning', 'of', 'programs', 'and', 'ways', 'to', 'finance', 'them', 'have', 'become', 'musts', 'if', 'the', 'state', 'in', 'the', 'next', 'few', 'years', 'is', 'to', 'avoid', 'crisis-to-crisis', 'government', '.'], ['This', 'session', ',', 'for', 'instance', ',', 'may', 'have', 'insured', 'a', 'financial', 'crisis', 'two', 'years', 'from', 'now', '.'], ['In', 'all', 'the', 'turmoil', ',', 'some', 'good', 'legislation', 'was', 'passed', '.'], ['Some', 'other', 'good', 'bills', 'were', 'lost', 'in', 'the', 'shuffle', 'and', 'await', 'future', 'action', '.'], ['Certainly', 'all', 'can', 'applaud', 'passage', 'of', 'an', 'auto', 'title', 'law', ',', 'the', 'school', 'bills', ',', 'the', 'increase', 'in', 'teacher', 'pensions', ',', 'the', 'ban', 'on', 'drag', 'racing', ',', 'acceptance', 'by', 'the', 'state', 'of', 'responsibility', 'for', 'maintenance', 'of', 'state', 'roads', 'in', 'municipalities', 'at', 'the', 'same', 'rate', 'as', 'outside', 'city', 'limits', ',', 'repeal', 'of', 'the', 'college', 'age', 'limit', 'law', 'and', 'the', 'road', 'maintenance', 'bond', 'issue', '.']]\n",
            "\n",
            "\n",
            "\n",
            "Test data: \n",
            "[['They', 'neither', 'liked', 'nor', 'disliked', 'the', 'Old', 'Man', '.'], ['To', 'them', 'he', 'could', 'have', 'been', 'the', 'broken', 'bell', 'in', 'the', 'church', 'tower', 'which', 'rang', 'before', 'and', 'after', 'Mass', ',', 'and', 'at', 'noon', ',', 'and', 'at', 'six', 'each', 'evening', '--', 'its', 'tone', ',', 'repetitive', ',', 'monotonous', ',', 'never', 'breaking', 'the', 'boredom', 'of', 'the', 'streets', '.'], ['The', 'Old', 'Man', 'was', 'unimportant', '.'], ['Yet', 'if', 'he', 'were', 'not', 'there', ',', 'they', 'would', 'have', 'missed', 'him', ',', 'as', 'they', 'would', 'have', 'missed', 'the', 'sounds', 'of', 'bees', 'buzzing', 'against', 'the', 'screen', 'door', 'in', 'early', 'June', ';', ';'], ['or', 'the', 'smell', 'of', 'thick', 'tomato', 'paste', '--', 'the', 'ripe', 'smell', 'that', 'was', 'both', 'sweet', 'and', 'sour', '--', 'rising', 'up', 'from', 'aluminum', 'trays', 'wrapped', 'in', 'fly-dotted', 'cheesecloth', '.'], ['Or', 'the', 'surging', 'whirling', 'sounds', 'of', 'bats', 'at', 'night', ',', 'when', 'their', 'black', 'bodies', 'dived', 'into', 'the', 'blackness', 'above', 'and', 'below', 'the', 'amber', 'street', 'lights', '.'], ['Or', 'the', 'bay', 'of', 'female', 'dogs', 'in', 'heat', '.'], ['They', 'never', 'called', 'him', 'by', 'name', ',', 'although', 'he', 'had', 'one', '.'], ['Filippo', 'Rossi', ',', \"that's\", 'what', 'he', 'was', 'called', 'in', 'the', 'old', 'country', ';', ';'], ['but', 'here', 'he', 'was', 'just', 'Signore', 'or', 'the', 'Old', 'Man', '.']]\n"
          ]
        }
      ],
      "source": [
        "train_lines = brown.sents(categories=['adventure', 'editorial', 'fiction',\n",
        "                                      'hobbies', 'humor', 'lore', 'mystery' 'reviews',\n",
        "                                     ])\n",
        "test_lines = brown.sents(categories=['romance'])\n",
        "\n",
        "print(f\"Training data: \\n{train_lines[:10]}\")\n",
        "print(\"\\n\\n\")\n",
        "print(f\"Test data: \\n{test_lines[:10]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cssrSED6o-H"
      },
      "source": [
        "In the following section you are provided `train_sentences` and `test_sentences` as list of lowercased sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYaovuk36o-I",
        "outputId": "e785ddaf-f3df-46cf-ab12-ac3e6f388e01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training sentences: \n",
            "['assembly session brought much good', 'the general assembly , which adjourns today , has performed in an atmosphere of crisis and struggle from the day it convened .', 'it was faced immediately with a showdown on the schools , an issue which was met squarely in conjunction with the governor with a decision not to risk abandoning public education .', 'there followed the historic appropriations and budget fight , in which the general assembly decided to tackle executive powers .', 'the final decision went to the executive but a way has been opened for strengthening budgeting procedures and to provide legislators information they need .', 'long-range planning of programs and ways to finance them have become musts if the state in the next few years is to avoid crisis-to-crisis government .', 'this session , for instance , may have insured a financial crisis two years from now .', 'in all the turmoil , some good legislation was passed .', 'some other good bills were lost in the shuffle and await future action .', 'certainly all can applaud passage of an auto title law , the school bills , the increase in teacher pensions , the ban on drag racing , acceptance by the state of responsibility for maintenance of state roads in municipalities at the same rate as outside city limits , repeal of the college age limit law and the road maintenance bond issue .']\n",
            "\n",
            "\n",
            "\n",
            "Test sentences: \n",
            "['they neither liked nor disliked the old man .', 'to them he could have been the broken bell in the church tower which rang before and after mass , and at noon , and at six each evening -- its tone , repetitive , monotonous , never breaking the boredom of the streets .', 'the old man was unimportant .', 'yet if he were not there , they would have missed him , as they would have missed the sounds of bees buzzing against the screen door in early june ; ;', 'or the smell of thick tomato paste -- the ripe smell that was both sweet and sour -- rising up from aluminum trays wrapped in fly-dotted cheesecloth .', 'or the surging whirling sounds of bats at night , when their black bodies dived into the blackness above and below the amber street lights .', 'or the bay of female dogs in heat .', 'they never called him by name , although he had one .', \"filippo rossi , that's what he was called in the old country ; ;\", 'but here he was just signore or the old man .']\n"
          ]
        }
      ],
      "source": [
        "train_sentences = [\" \".join(sent).lower() for sent in train_lines]\n",
        "test_sentences = [\" \".join(sent).lower() for sent in test_lines]\n",
        "\n",
        "print(f\"Training sentences: \\n{train_sentences[:10]}\")\n",
        "print(\"\\n\\n\")\n",
        "print(f\"Test sentences: \\n{test_sentences[:10]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRoeWXnI6o-I"
      },
      "source": [
        "### Exercise 1 : Remove punctuation and add start and end tokens.\n",
        "<b><div style=\"text-align: right\">[POINTS: 2]</div></b>\n",
        "\n",
        "`train_sentences` and `test_sentences` contain lowercased list of sentences. However, they still contain punctuations such as `(\".\", \"?\", \",\", \"'\", \"-\")` etc. Your task is to remove those punctuations. Also, after removing the punctuations, your task is to add start `'<s>'` and end `'</s>'` tokens.\n",
        "\n",
        "**Tasks:**\n",
        "\n",
        "* Remove punctuations\n",
        "* Add start and end tokens to each sentences\n",
        "* Return the list of sentences with removed puncuations and added start and end tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "IZ0oDRLg6o-J",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0b738f2ce0fcff926cd25609f1260447",
          "grade": false,
          "grade_id": "cell-2585baf5b9165ee9",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "tags": [
          "Ex-1-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "SOS = \"<s> \"\n",
        "EOS = \"</s>\"\n",
        "\n",
        "def basic_preprocess(sentences):\n",
        "    \"\"\"\n",
        "    Lowercase all words and remove punctuations.\n",
        "    And add start and end tokens.\n",
        "\n",
        "    For example:\n",
        "    Args:\n",
        "        senetences(list) : ['this is first sentence .', 'this is second sentence .']\n",
        "    Returns:\n",
        "        sents(list): ['<s> this is first sentence </s>', '<s> this is second sentence </s>']\n",
        "    \"\"\"\n",
        "\n",
        "    sents = None\n",
        "    ### Ex-1-Task-1\n",
        "    ### BEGIN SOLUTION\n",
        "    # YOUR CODE HERE\n",
        "    import re\n",
        "    sents = []\n",
        "    for sentence in sentences:\n",
        "    sents = [SOS + sent.translate(str.maketrans('','',string.punctuation)) + EOS for sent in sentences]\n",
        "    # raise NotImplementedError()\n",
        "    ### END SOLUTION\n",
        "\n",
        "    return sents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "3xrMQI016o-J",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9b0ce166d98222c6f130a75791b445c9",
          "grade": true,
          "grade_id": "cell-0dd5b5f562d07b2b",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false
        },
        "tags": [
          "Ex-1-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "# Intentionally Left Blank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Gf6fxz46o-K"
      },
      "outputs": [],
      "source": [
        "processed_train_sentences = basic_preprocess(train_sentences)\n",
        "processed_test_sentences = basic_preprocess(test_sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhIyoMZs6o-K"
      },
      "source": [
        "### Exercise 2 : Replace words with count = 1 with '< UNK>' token and create word tokens\n",
        "<b><div style=\"text-align: right\">[POINTS: 2]</div></b>\n",
        "\n",
        "`processed_train_sentences` and `processed_test_sentences` contain the processed sentences as a list. Your task is to check all the word tokens which appear only once in the corpus and replace them with `'<UNK>'` token. The function should return all of the sequence of words in the corpus in a single list.\n",
        "\n",
        "For example, if the sample input is:\n",
        "```\n",
        "['<s> this is first sentence </s>', '<s> this is second sentence </s>']\n",
        "```\n",
        "Here the words `'first'` and `'second'` appear only once in the corpus.\n",
        "The output should be:\n",
        "```\n",
        "['<s>', 'this', 'is', '<UNK>', 'sentence', '</s>', '<s>', 'this', 'is', '<UNK>', 'sentence', '</s>']\n",
        "```\n",
        "\n",
        "\n",
        "**Task:**\n",
        "\n",
        "*  Replace word counts=1 in the corpus with < UNK> token and create individual word tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "W-ase6PM6o-K",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "387bf631cda3fdde821c885b6cef2ab3",
          "grade": false,
          "grade_id": "cell-899c44a80a1cbafb",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "tags": [
          "Ex-2-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "UNK = \"<UNK>\"\n",
        "\n",
        "def generate_tokens(sentences):\n",
        "    \"\"\"\n",
        "    Takes a list of sentences with start and end tokens.\n",
        "    The function should replace the words which occur only once in the corpus with\n",
        "    '<UNK>' token and return the list of all tokens.\n",
        "    For example:\n",
        "    Args:\n",
        "        sentences(list):\n",
        "        ['<s> this is first sentence </s>', '<s> this is second sentence </s>']\n",
        "\n",
        "    Returns:\n",
        "        tokens_with_unk(list):\n",
        "        ['<s>', 'this', 'is', '<UNK>', 'sentence', '</s>', '<s>', 'this', 'is', '<UNK>', 'sentence', '</s>']\n",
        "\n",
        "    \"\"\"\n",
        "    tokens = \" \".join(sentences).split()\n",
        "    vocab = nltk.FreqDist(tokens)\n",
        "\n",
        "    tokens_with_unk = None\n",
        "    ### Ex-2-Task-1\n",
        "    ### BEGIN SOLUTION\n",
        "    from collections import Counter\n",
        "    word_counts = Counter(tokens)\n",
        "    corpus_with_unk = ' '.join(['<UNK>' if word_counts[word] == 1 else word for word in tokens])\n",
        "    tokens_with_unk = corpus_with_unk.split()\n",
        "    # YOUR CODE HERE\n",
        "    ### END SOLUTION\n",
        "\n",
        "    return tokens_with_unk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "11uqMdIz6o-L",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8c6ca720c915cb688ad9408ee040d347",
          "grade": true,
          "grade_id": "cell-9acfe5e3136bd33d",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false
        },
        "tags": [
          "Ex-2-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "# Intentionally Left Blank\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_PZpvch6o-M"
      },
      "outputs": [],
      "source": [
        "train_tokens = generate_tokens(processed_train_sentences)\n",
        "test_tokens = generate_tokens(processed_train_sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dco3nKiA6o-M"
      },
      "source": [
        "### Exercise 3 : Create n-grams and get their counts\n",
        "<b><div style=\"text-align: right\">[POINTS: 2]</div></b>\n",
        "\n",
        "Now, it's time to create n-grams from the tokens generated from Exercise 2. Your task is to return unique n-grams with their corresponding counts.\n",
        "\n",
        "**Task:**\n",
        "* Create n-grams and return unique n-grams with their corresponding counts.\n",
        "\n",
        "Hint: `nltk.ngrams()` and `nltk.FreqDist()` functions may be helpful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "M0hUDdqR6o-N",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b35692bfa287cd84b71361eaf99880d6",
          "grade": false,
          "grade_id": "cell-c10d71fd459b01c2",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "tags": [
          "Ex-3-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "def ngrams(tokens, n=2):\n",
        "    \"\"\"\n",
        "    Create n-grams and return unique n-grams with their corresponding counts.\n",
        "\n",
        "    Args:\n",
        "        tokens (list): list of tokens\n",
        "        n(int) = 1 for unigram, 2 for bigram\n",
        "\n",
        "    Returns:\n",
        "    n-grams(dict): dictionary of n-grams as a tuple and it's corresponding count.\n",
        "\n",
        "    Example:\n",
        "        tokens = ['<s>', 'this', 'is', '<UNK>', 'sentence', '</s>',\n",
        "                '<s>', 'this', 'is', '<UNK>', 'sentence', '</s>']\n",
        "        For n = 1,\n",
        "\n",
        "        n_grams:{\n",
        "                ('<s>',): 2,\n",
        "                ('this',): 2,\n",
        "                ('is',): 2,\n",
        "                ('<UNK>',): 2,\n",
        "                ('sentence',): 2,\n",
        "                ('</s>',): 2\n",
        "                }\n",
        "\n",
        "        For n = 2,\n",
        "\n",
        "        n_grams: {\n",
        "                ('<s>', 'this') : 2,\n",
        "                ('this', 'is') : 2,\n",
        "                ('is', '<UNK>') : 2,\n",
        "                ('<UNK>', 'sentence') : 2,\n",
        "                ('</s>' '<s>') : 1,\n",
        "                ('sentence', '</s>') : 2\n",
        "                }\n",
        "    \"\"\"\n",
        "    ngram_dicts = None\n",
        "    ### Ex-3-Task-1\n",
        "    ### BEGIN SOLUTION\n",
        "    # YOUR CODE HERE\n",
        "    from nltk import ngrams, FreqDist\n",
        "    n_grams = list(ngrams(tokens, n))\n",
        "    ngram_freq = FreqDist(n_grams)\n",
        "    ngram_dicts = dict(ngram_freq)\n",
        "    # raise NotImplementedError()\n",
        "    ### END SOLUTION\n",
        "\n",
        "    return ngram_dicts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "D7JKeJ2m6o-N",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a5d73bfc7b0640eb1375ccb3f297b2d9",
          "grade": true,
          "grade_id": "cell-8f1ba92468db5a67",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false
        },
        "tags": [
          "Ex-3-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "# Intentionally Left Blank\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKi7Waf36o-O"
      },
      "outputs": [],
      "source": [
        "n = 2\n",
        "\n",
        "bigram_dicts = ngrams(train_tokens, n)\n",
        "unigram_dicts = ngrams(train_tokens, n-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dqsji-V86o-O",
        "outputId": "4ae7a1f7-34f6-448c-9fb5-59b0a762bed3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15086"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "vocab = nltk.FreqDist(train_tokens)\n",
        "vocab_size = len(vocab)\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bVchYq56o-O"
      },
      "source": [
        "### Exercise 4 : Laplace Smoothing\n",
        "<b><div style=\"text-align: right\">[POINTS: 3]</div></b>\n",
        "\n",
        "We know that the Laplace smoothing for bigram is given as:\n",
        "\n",
        "$$\n",
        "P_{Laplace}^{*}(w_n|w_{n-1}) = \\frac{\\text{count}(w_{n-1}w_n) + 1}{\\text{count}(w_{n-1}) + V}\n",
        "$$\n",
        "\n",
        "Here, $w_{n-1}$ is the previous word and $w_n$ is the present word of the bigram. Also, $V$ is the vocab size of the corpus.\n",
        "\n",
        "For eg:\n",
        "$$P_{Laplace}^{*}\\text{(\"great\"| \"the\")} = \\frac{\\text{count(\"the\", \"great\") + 1}}{\\text{count(\"the\")} + \\text{vocab_size}}$$\n",
        "\n",
        "**Task:**\n",
        "* Apply laplace smoothing for a bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "Agr5FSho6o-P",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4d014dee1a310fed84db8fb2b823cc4a",
          "grade": false,
          "grade_id": "cell-f4f953ddf2d6d675",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "tags": [
          "Ex-4-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "def smoothed_bigram_prob(bigram, bigram_count, unigram_dicts, vocab_size):\n",
        "\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        bigram (a tuple): a tuple of bigrams for ex: ('the', 'great')\n",
        "        bigram_count(int): count of bigram\n",
        "        unigram_dicts: dictionary containing unigrams and their corresponding counts\n",
        "        vocab_size: vocab size of the corpus\n",
        "\n",
        "    Returns:\n",
        "        smoothed_prob(float): Smoothed probability of the bigram.\n",
        "    \"\"\"\n",
        "\n",
        "    unigram = None\n",
        "    unigram_count = None\n",
        "    smoothed_prob = None\n",
        "    ### Ex-4-Task-1\n",
        "    ### BEGIN SOLUTION\n",
        "    # YOUR CODE HERE\n",
        "    unigram = list(nltk.ngrams(bigram,1))\n",
        "    unigram_count = unigram_dicts[unigram[0]]\n",
        "    smoothed_prob = (bigram_count + 1) / (unigram_count + vocab_size)\n",
        "    # raise NotImplementedError()\n",
        "    ### END SOLUTION\n",
        "    return smoothed_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "IB0XyVp96o-P",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b7bc3adf2b877eeca74af609a2026f3e",
          "grade": true,
          "grade_id": "cell-8229ab29523521aa",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false
        },
        "tags": [
          "Ex-4-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "# Intentionally Left Blank\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIvIj-PT6o-P"
      },
      "outputs": [],
      "source": [
        "def smoothing(bigram_dicts):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        bigram_dicts (dict): dictionary items containing bigram tuple and their corresponding count.\n",
        "\n",
        "    Returns:\n",
        "        (dict) : dictionary items containing bigram tuple and thier smoothed probability.\n",
        "    \"\"\"\n",
        "    return { n_gram: smoothed_bigram_prob(n_gram, count, unigram_dicts, vocab_size) \\\n",
        "            for n_gram, count in bigram_dicts.items() }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnfNILBw6o-P",
        "outputId": "e526b3be-c708-4054-f8d0-8e58bd68ac76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('</s>', '<s>'), 1.4589685801405277),\n",
              " (('of', 'the'), 0.2021742012461885),\n",
              " (('<s>', 'the'), 0.16200450749038844),\n",
              " (('in', 'the'), 0.13568871801670424),\n",
              " (('the', '<UNK>'), 0.09909850192231208),\n",
              " (('<UNK>', '</s>'), 0.09770648283176454),\n",
              " (('<s>', 'he'), 0.0906138141323081),\n",
              " (('to', 'the'), 0.08086968049847541),\n",
              " (('on', 'the'), 0.06370144504838923),\n",
              " (('<UNK>', 'and'), 0.0556144769985417),\n",
              " (('<UNK>', '<UNK>'), 0.05362587829775951),\n",
              " (('<s>', 'it'), 0.05216757258385258),\n",
              " (('and', 'the'), 0.050178973883070396),\n",
              " (('a', '<UNK>'), 0.04971496751955455),\n",
              " (('<s>', 'i'), 0.04746122232533475),\n",
              " (('and', '<UNK>'), 0.04480975739095851),\n",
              " (('at', 'the'), 0.042158292456582265),\n",
              " (('for', 'the'), 0.041429139599628795),\n",
              " (('<UNK>', 'of'), 0.039506827522206016),\n",
              " (('<s>', 'but'), 0.0382473816783773)]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "model = smoothing(bigram_dicts)\n",
        "sorted(model.items(), key=lambda x: x[1], reverse=True)[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ilHn5Ps6o-Q"
      },
      "source": [
        "### Exercise 5 : Calculate perplexity.\n",
        "<b><div style=\"text-align: right\">[POINTS: 1]</div></b>\n",
        "\n",
        "We know the perplexity of the test set for bigram is given as:\n",
        "$$\n",
        "PP(S) = \\sqrt[N]{\\frac{1}{\\prod \\limits_{i=1}^{N} P(w_i | w_{i-1})}}    \\tag{1}\n",
        "$$\n",
        "\n",
        "i.e\n",
        "$$\n",
        "PP(S) = ({\\prod \\limits_{i=1}^{N} P(w_i | w_{i-1})})^{\\frac{-1}{N}} \\tag{2}\n",
        "$$\n",
        "\n",
        "Take log on both sides:\n",
        "$$\n",
        "log(PP(S)) = {-\\frac{1}{N}} \\sum \\limits_{i=1}^{N}{log(P(w_i | w_{i-1}))} \\tag{3}\n",
        "$$\n",
        "\n",
        "\n",
        "So, the $PP(S)$ is exponential of sum of log probabilities, normalized by the number of tokens in the test set. \\\n",
        "i.e.\n",
        "$$\n",
        "PP(S) = \\exp(-{\\frac{1}{N}} \\sum \\limits_{i=1}^{N}{log(P(w_i | w_{i-1}))})  \\tag{4}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "**Task:**\n",
        "* You are given the probabilities of the test set in a list. Calculate the perplexity of the test set, using equation (4)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TKfw2w56o-Q"
      },
      "outputs": [],
      "source": [
        "masks = [[1,1], [1, 0], [0, 1], [0, 0]]\n",
        "\n",
        "def convert_oov(ngram):\n",
        "    \"\"\"Converts, if necessary, a given n-gram to one which is known by the model.\n",
        "    Args:\n",
        "        ngram (tuple): a bigram tuple. for ex: (\"the\", \"great\")\n",
        "    Returns:\n",
        "        The n-gram with <UNK> tokens in certain positions such that the model\n",
        "        contains an entry for it.\n",
        "\n",
        "    \"\"\"\n",
        "    mask = lambda ngram, bitmask: tuple((token if flag == 1 else \"<UNK>\" for token,flag in zip(ngram, bitmask)))\n",
        "\n",
        "    ngram = (ngram,) if type(ngram) is str else ngram\n",
        "    for possible_known in [mask(ngram, bitmask) for bitmask in masks]:\n",
        "        if possible_known in model:\n",
        "            return possible_known"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXZa_75z6o-Q"
      },
      "outputs": [],
      "source": [
        "test_ngrams = nltk.ngrams(test_tokens, 2)\n",
        "N = len(test_tokens)\n",
        "known_ngrams  = (convert_oov(ngram) for ngram in test_ngrams)\n",
        "probs = [model[ngram] for ngram in known_ngrams]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "nQBxo48r6o-Q",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c93f57b0a09dbfb483917d0f0d3835c7",
          "grade": false,
          "grade_id": "cell-440b8941bad5499b",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "tags": [
          "Ex-5-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def perplexity(prob, N):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        probs(list): list of test probabilities.\n",
        "        N(int): Number of tokens in the test set.\n",
        "\n",
        "    Returns:\n",
        "        perplexity(float): Perplexity of the model in the test set.\n",
        "    \"\"\"\n",
        "    perplexity = None\n",
        "    ### Ex-5-Task-1\n",
        "    ### BEGIN SOLUTION\n",
        "    # YOUR CODE HERE\n",
        "    perplexity = math.exp((-1/N) * sum([math.log(p) for p in prob]) )\n",
        "    # raise NotImplementedError()\n",
        "    ### END SOLUTION\n",
        "    return perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "j0srjDPn6o-Q",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d1a5dec514c21b11b5138af17bfd6b71",
          "grade": true,
          "grade_id": "cell-0f0fa656aab6075f",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "tags": [
          "Ex-5-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "# Intentionally Left Blank\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dUOj_GX6o-Q",
        "outputId": "f4c840bf-2cd2-4ffc-f047-fcb84dab854e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity of the model is: 0.000997781885014523\n"
          ]
        }
      ],
      "source": [
        "pps = perplexity(probs, N)\n",
        "print(f\"Perplexity of the model is: {pps}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL1J0rnZ6o-R"
      },
      "source": [
        "## Sentence Generation with n-grams\n",
        "Now that our bigram model is ready, let's generate some sample sentences from the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7y_pBQy6o-R"
      },
      "outputs": [],
      "source": [
        "\n",
        "import math\n",
        "import random\n",
        "def best_candidate(prev, i, without=[]):\n",
        "    \"\"\"Choose the most likely next token given the previous (n-1) tokens.\n",
        "    Args:\n",
        "        prev (tuple of str): the previous n-1 tokens of the sentence.\n",
        "        i (int): which candidate to select if not the most probable one.\n",
        "        without (list of str): tokens to exclude from the candidates list.\n",
        "    Returns:\n",
        "        A tuple with the next most probable token and its corresponding probability.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    blacklist  = [\"<UNK>\"] + without\n",
        "    candidates = ((ngram[-1], prob) for ngram, prob in model.items() if ngram[:-1]==prev)\n",
        "    candidates = filter(lambda candidate: candidate[0] not in blacklist, candidates)\n",
        "    candidates = sorted(candidates, key=lambda candidate: candidate[1], reverse=True)\n",
        "\n",
        "    if len(candidates) == 0:\n",
        "        return (\"</s>\", 1)\n",
        "    else:\n",
        "        candidate_index = int((random.randint(0, len(candidates)))/2)\n",
        "        return candidates[candidate_index if prev != () and prev[-1] != \"<s>\" else i]\n",
        "\n",
        "def generate_sentences(num, min_len=12, max_len=24):\n",
        "    \"\"\"Generate random sentences using the language model.\n",
        "    Args:\n",
        "        num (int): the number of sentences to generate.\n",
        "        min_len (int): minimum allowed sentence length.\n",
        "        max_len (int): maximum allowed sentence length.\n",
        "    Yields:\n",
        "        A tuple with the generated sentence and the combined probability\n",
        "        (in log-space) of all of its n-grams.\n",
        "\n",
        "    \"\"\"\n",
        "    for i in range(num):\n",
        "        sent, prob = [\"<s>\"], 1\n",
        "        while sent[-1] != \"</s>\":\n",
        "            prev = tuple(sent[-(1):])\n",
        "            blacklist = sent + ([\"</s>\"] if len(sent) < min_len else [])\n",
        "            next_token, next_prob = best_candidate(prev, i, without=blacklist)\n",
        "            sent.append(next_token)\n",
        "            prob *= next_prob\n",
        "\n",
        "            if len(sent) >= max_len:\n",
        "                sent.append(\"</s>\")\n",
        "\n",
        "        yield ' '.join(sent), -1/math.log(prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peN2HZR36o-R",
        "outputId": "93bc9fb1-e39b-465a-9304-63eef4a45bbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating sentences...\n",
            "<s> the transmutation of including new game whitetail hunter this kind mr america was quiet and bend handle a wrinkled heavy weight in crisp </s> (0.00522)\n",
            "<s> he declared his records because were given number on behind you did </s> (0.00955)\n",
            "<s> it stands in jeopardy </s> (0.03661)\n",
            "<s> i cant expect you stress and postponed only on toward full communism established that feeding lowmoisture corn in individuals to germany it doesnt </s> (0.00526)\n",
            "<s> but pansy seeds so then installed over in jerusalem why arent the competition at cypress swamp </s> (0.00703)\n",
            "<s> in only to note however it floating ice cream six times of 1927 </s> (0.00891)\n",
            "<s> a waterfront shouting there evidence the boss was tried her breasts suffocating one morning classes riding down early stages of computing compression ratio </s> (0.00514)\n",
            "<s> and bow down the towns perched on weekends enable us all teachers are realizing that boy asserted would reduce their days she took </s> (0.00528)\n",
            "<s> they may prove the relative comfort are noble experiment with scenic spot but each lever to gain in counties and expensive than outright </s> (0.00519)\n",
            "<s> she greeted him straightened out over my double duty on net farm cannot but that bothers all american girl he stared in two </s> (0.00527)\n"
          ]
        }
      ],
      "source": [
        "print(\"Generating sentences...\")\n",
        "for sentence, prob in generate_sentences(num = 10):\n",
        "    print(\"{} ({:.5f})\".format(sentence, prob))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyAAGDrP6o-R"
      },
      "source": [
        "Here in this assignment, we build a bigram model using Laplace smoothing techniques and we calculated perplexity of the model in the test set.\n",
        "\n",
        "Then, we generated some sample sentences from the bigram model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCvDL9hR6o-R"
      },
      "source": [
        "---\n",
        "\n",
        "**Congratulations for successfully completing the assignment**.\n",
        "\n",
        "Good Luck going forward with the course.\n",
        "See you in the next chapter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKOXFKFd6o-S"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}