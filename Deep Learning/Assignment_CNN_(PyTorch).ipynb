{"cells":[{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"oajiTSAMA-N5","nbgrader":{"cell_type":"markdown","checksum":"cabf4b254f6153d7b062b49d08aded7e","grade":false,"grade_id":"cell-43d40d36d10237c6","locked":true,"schema_version":3,"solution":false}},"source":["<h1><b>Assignment : CNN Classification on CIFAR-10 using PyTorch</b></h1>\n","\n","Now that you have understood the working of a Convolutional Neural Network with all of its layers, it is now time to implement your knowledge in code. In this assignment, you will build a CNN classifier using PyTorch. \n","\n","In the L1 course, you built a classifier model using the **PyTorch**.What is even more interesting is that, we will be visualizing the intermediate steps and shapes of a CNN in even more detail. \n","\n","In this assignment, we will be using the **'CIFAR10'** dataset from PyTorch datasets. The dataset consists of 60,000 sample images with two default splits: train and test. It contains images from 10 different classes of objects with labels 0-9.\n","Below, you can see the different classes in the cifar10 dataset. It consists of 10 output classes:\n","\n","1. Airplane\n","2. Automobile\n","3. Bird\n","4. Cat\n","5. Deer\n","6. Dog\n","7. Frog\n","8. Horse\n","9. Ship\n","10. Truck"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"kZ8ik87fBZKl","nbgrader":{"cell_type":"markdown","checksum":"289ca04d34b23a06fe22871333b0e291","grade":false,"grade_id":"cell-9a6d6c16e5e370ad","locked":true,"schema_version":3,"solution":false}},"source":["<h2><b>Importing Necessary Libraries</b></h2>\n","\n","We will first start my importing the necessary libraries for our assignment. Specific libraries will be imported as we move further."]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"id":"HK4ss5PYe1M4","nbgrader":{"cell_type":"code","checksum":"c07938df28131d726ea97cbbdb59338f","grade":false,"grade_id":"cell-09d9157bb516a8ba","locked":true,"schema_version":3,"solution":false,"task":false}},"outputs":[],"source":["# imports\n","import os\n","import pickle\n","import numpy as np\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","\n","print(torch.__version__)"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"mmt5OsayBeRX","nbgrader":{"cell_type":"markdown","checksum":"1f13438caaffcba262a0d7c2b6c3a53e","grade":false,"grade_id":"cell-af9c42f17a68770c","locked":true,"schema_version":3,"solution":false}},"source":["<h2><b>Loading the dataset</b></h2>\n","\n","As mentioned before, we will be using the **cifar10 dataset** from torchvision datasets for our classification task. Here, we have loaded the dataset. By default, it is split intro train and test sets. We will now use this default split to separate the dataset into the training and testing data."]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"id":"rQAfvlQWfByy","nbgrader":{"cell_type":"code","checksum":"dcf50d3258c64dfcc9e57b304a7ead86","grade":false,"grade_id":"cell-57d8683aaef5660f","locked":true,"schema_version":3,"solution":false}},"outputs":[],"source":["import torchvision\n","import torchvision.transforms as transforms\n","\n","transform = transforms.Compose(\n","    [transforms.ToTensor(),  # To convert to tensor with compatible data type i.e., float32\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  # To normalize image\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"mA0-HSUABtJJ","nbgrader":{"cell_type":"markdown","checksum":"e48fef9c093e21c1b0dd6943c1f28930","grade":false,"grade_id":"cell-089f51a920629b32","locked":true,"schema_version":3,"solution":false}},"source":["Here, you can see that the dataset contains image samples and labels. Each image is of size `32x32x3`. "]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"id":"xbBb75gtfEP9","nbgrader":{"cell_type":"code","checksum":"be7c38816e84899d16dd4f1aac4bdcc7","grade":false,"grade_id":"cell-94a0853df495a9b6","locked":true,"schema_version":3,"solution":false}},"outputs":[],"source":["print(trainset.data.shape)\n","print(testset.data.shape)"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"PRgtUwXxCB37","nbgrader":{"cell_type":"markdown","checksum":"73ae5fc9110735a7bb65f14e532c48ff","grade":false,"grade_id":"cell-2e812659c40d4255","locked":true,"schema_version":3,"solution":false}},"source":["We can even plot image samples and their labels from one of the sets. Here, we have imported matplotlib pyplot for the plotting operation."]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"id":"4r_aDRJefHCw","nbgrader":{"cell_type":"code","checksum":"6fb9cf95bb7369c51f6d1857ff8fc94f","grade":false,"grade_id":"cell-c68bfd9b4db7d35c","locked":true,"schema_version":3,"solution":false,"task":false}},"outputs":[],"source":["from operator import le\n","import matplotlib.pyplot as plt\n","\n","# Show the first two images and labels from the training set\n","get_label_name = {v: k for k, v in trainset.class_to_idx.items()}\n","np.random.seed(49)\n","for idx in np.random.randint(0, len(trainset), size=2):\n","    image, label = trainset.data[idx], trainset.targets[idx]\n","    plt.figure()\n","    plt.imshow(image)\n","    plt.title(get_label_name[label])"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"OKElqqLzTNIw","nbgrader":{"cell_type":"markdown","checksum":"41cb5fd77ac525228052336cd14b3e62","grade":false,"grade_id":"cell-656c731201a6d8a0","locked":true,"schema_version":3,"solution":false}},"source":["<h2><b>Exercise 1: Layer Implementations for CNN architecture</b></h2>\n","\n","<b>[POINTS: 6]</b>\n","\n","Now for the exciting part, let us dive into the model building section. But before that, here we will experiment with custom layer building from PyTorch. You will be building three custom layers: <b>Conv2D, Max-pool and Dense layers </b> using nn.Module. The task might look a bit lengthy, but if you follow the instructions step-by-step, you will end up with your very own custom layers. For your ease, we have initialized a Glorot Uniform(Xavier Uniform in PyTorch) initializer with a seed value for parameter initialization.\n"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"LZNC9UStCkx2","nbgrader":{"cell_type":"markdown","checksum":"4705ab72f5521fd3a88062e60d8bb824","grade":false,"grade_id":"cell-3a6a2f351ea1c59b","locked":true,"schema_version":3,"solution":false}},"source":["<h3><b>Task 1:</b></h3>\n","<b>[POINTS: 2]</b>\n","\n","(2 lines of code)\n","\n","Fill in the `forward` function for the custom Conv2D layer class with the following steps:\n","1.   Pass the input through the `F.conv2d`. Use the weights, the bias the padding and the strides initialized in the `__init__` function above.\n","2. Finally, pass the input through a `F.relu` operation.\n","\n","\n","<h3><b>Task 2:</b></h3>\n","<b>[POINTS: 2]</b>\n","\n","(1 line of code)\n","\n","Fill in the `forward` function for the custom MaxPool layer class with the following steps:\n","1.   Pass the input through the `F.max_pool2d`. Use the attributes initialized in the `__init__` function to pass to this function.\n","\n","\n","<h3><b>Task 3:</b></h3>\n","<b>[POINTS: 2]</b>\n","\n","(1 line of code)\n","\n","Fill in the `forward` function for the custom Dense layer class with the following steps:\n","1.   Use the `torch.mm` to multiply the weights with the input and add the result to the bias. Use the weights and bias initialized in the `__init__` function.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"id":"DbKq7tZas6RK","nbgrader":{"cell_type":"code","checksum":"fcc0427a8f950684e5cb956a61a23a98","grade":false,"grade_id":"cell-07a69dbe3ec726ac","locked":false,"schema_version":3,"solution":true},"tags":["Ex-1-Task-1"]},"outputs":[],"source":["### Ex-1-Task-1\n","class Conv2D(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding='same'):\n","        \"\"\"\n","        This function initializes the parameters for a conv2D layer\n","\n","        Parameters\n","        ------------\n","        in_channels : int\n","        Number of channels in the input image\n","\n","        out_channels : int\n","        Number of channels produced by the convolution\n","\n","        kernel_size : int or tuple\n","        Size of the convolving kernel \n","\n","        stride : int or tuple\n","        Stride of the convolution. Default: 1\n","\n","        padding: int, tuple or str\n","        Padding added to all four sides of the input. Default: 'same'\n","        \"\"\"\n","        super(Conv2D, self).__init__()\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.kernel_size = (kernel_size, kernel_size) if isinstance(kernel_size, int) else kernel_size\n","        self.stride = stride\n","        self.padding = padding\n","\n","        self.weight = nn.Parameter(\n","            torch.nn.init.xavier_uniform_(\n","                torch.empty(\n","                    (self.out_channels, self.in_channels, *self.kernel_size),\n","                    requires_grad=True\n","                )\n","            )\n","        )\n","        self.bias = nn.Parameter(\n","            torch.zeros((self.out_channels,), requires_grad=True)\n","        )\n","\n","    def forward(self, x):\n","        \"\"\"\n","        This function performs convolution operation on the input\n","        Parameters\n","        ------------\n","        x : tensor, float32\n","        Input image to the convolution layer\n","\n","        Returns\n","        ------------\n","        x : tensor, float32\n","        feature map output from the last layer\n","        \"\"\"\n","        # Exercise 1 | Task 1\n","        ### BEGIN SOLUTION\n","        # your code here\n","        raise NotImplementedError\n","        ### END SOLUTION\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"id":"0wIn94ZFM1CD","nbgrader":{"cell_type":"code","checksum":"2f2f6523a344a0bcbe808a2e0e47724d","grade":true,"grade_id":"cell-c41e5789b7ec1560","locked":true,"points":2,"schema_version":3,"solution":false},"tags":["Ex-1-Task-1"]},"outputs":[],"source":["# INTENTIONALLY LEFT BLANK"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"id":"tUKp4cWBs-lx","nbgrader":{"cell_type":"code","checksum":"cf7c4ec6c7219f73b9a91d277289d4b8","grade":false,"grade_id":"cell-85129c19b67cd7c1","locked":false,"schema_version":3,"solution":true},"tags":["Ex-1-Task-2"]},"outputs":[],"source":["### Ex-1-Task-2\n","class MaxPool(nn.Module):\n","    def __init__(self, kernel_size, stride=None, padding=0):\n","        \"\"\"\n","        This function initializes the parameters for a maxpool layer\n","\n","        Parameters\n","        ------------\n","        kernel_size : int\n","        window height and width for the maxpooling window\n","\n","        stride : int\n","        the stride of the window. Default value is kernel_size\n","\n","        padding: int\n","        implicit zero padding to be added on both sides\n","        \"\"\"\n","        super(MaxPool, self).__init__()\n","        self.kernel_size = kernel_size\n","        self.stride = kernel_size if stride is None else stride\n","        self.padding = padding\n","\n","\n","    def forward(self, x): \n","        \"\"\"\n","        This function performs max-pool operation on the input\n","\n","        Parameters\n","        ------------\n","        x : tensor, float32\n","        Input image to the convolution layer\n","\n","        Returns\n","        ------------\n","        x : tensor, float32\n","        max-pooled output from the last layer\n","        \"\"\"\n","        # Exercise 1 | Task 2 \n","        ### BEGIN SOLUTION\n","        # your code here\n","        raise NotImplementedError\n","        ### END SOLUTION\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"id":"t4ybYYosQU78","nbgrader":{"cell_type":"code","checksum":"89e3d1c08369099a71b2714060f68b4c","grade":true,"grade_id":"cell-1f500a46605ceaa9","locked":true,"points":2,"schema_version":3,"solution":false},"tags":["Ex-1-Task-2"]},"outputs":[],"source":["# INTENTIONALLY LEFT BLANK"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"id":"zbQ_AtwDfKsg","nbgrader":{"cell_type":"code","checksum":"9cb7e83152c1cb3b5ced02ddc9a257e0","grade":false,"grade_id":"cell-2aa73e252e3f1adb","locked":false,"schema_version":3,"solution":true},"tags":["Ex-1-Task-3"]},"outputs":[],"source":["### Ex-1-Task-3\n","class Dense(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        \"\"\"\n","        This function initializes the parameters for a dense layer\n","        Parameters\n","        ------------- \n","        in_features : int\n","        shape of the input to the dense layer\n","\n","        out_features : int\n","        number of units in the dense layer\n","        \"\"\"\n","        super(Dense, self).__init__()\n","        self.in_features = in_features\n","        self.out_features =  out_features\n","        \n","        self.weight = nn.Parameter(\n","            torch.nn.init.xavier_uniform_(\n","                torch.empty(\n","                    (self.in_features, self.out_features),\n","                    requires_grad=True,\n","                )\n","            )\n","        )\n","        self.bias = nn.Parameter(\n","            torch.zeros((self.out_features,), requires_grad=True)\n","        )\n","\n","    def forward(self, x):\n","        \"\"\"\n","        This function performs dense operation on the input\n","        Parameters\n","        ------------\n","        x : tensor, float32\n","        Input flattened image to the convolution layer\n","\n","        Returns\n","        ------------\n","        x : tensor, float32\n","        linear operation output from the last layer\n","        \"\"\"\n","        # Exercise 1 | Task 3\n","        ### BEGIN SOLUTION\n","        # your code here\n","        raise NotImplementedError\n","        ### END SOLUTION"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"id":"4kpnCFAfQ-_N","nbgrader":{"cell_type":"code","checksum":"897e3ad72aa4668740ffaa97808d922d","grade":true,"grade_id":"cell-8e0f83f13311d486","locked":true,"points":2,"schema_version":3,"solution":false},"tags":["Ex-1-Task-3"]},"outputs":[],"source":["# INTENTIONALLY LEFT BLANK"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"gHDratO-TVAJ","nbgrader":{"cell_type":"markdown","checksum":"cc7a9820cb364ca794c4b061c657efc3","grade":false,"grade_id":"cell-5338780c03cf69fe","locked":true,"schema_version":3,"solution":false}},"source":["<h2><b>Exercise 2: Creating the CNN architecture</b></h2>\n","\n","<b>[POINTS: 4]</b>\n","\n","Now that you've made your custom layers ready, here you will be combining these layers to create a complete CNN model. We have created a Model called `CNNModel` for the purpose. The `__init__` function initializes all the necessary layers required for the model. The `forward` function passes the input through the layers initialized above.\n","\n","<h3><b>Task 1:</b></h3>\n","<b>[POINTS: 2]</b>\n","\n","(3 lines of code)\n","\n","Initialize the `c4, m2 and d1` layers for the model using the custom layers you created above.\n","1.   Use the filter_dim and the remaining elements from the channels and variables list, as the parameters for the `c4` convolution layer.\n","2. Use k = 2 as a parameter for the `m2` maxpooling layer\n","3. Finally, use the remaining elements from the dense_in_features and dense_out_features lists as parameters for the `d1` dense layer.\n","\n","\n","<h3><b>Task 2:</b></h3>\n","<b>[POINTS: 2]</b> \n","\n","(6 lines of code)\n","\n","Pass the input the following series of layers:\n","1. c4\n","2. m2\n","3. dropout\n","4. Reshape layer to flatten the input before passing through the dense layer \n","5. d1\n","6. Relu layer\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"id":"ex6AB4MSfZyA","nbgrader":{"cell_type":"code","checksum":"10825b214641b226d982e705ca657d98","grade":false,"grade_id":"cell-43fc74088a15856f","locked":false,"schema_version":3,"solution":true},"tags":["Ex-2-Task-1"]},"outputs":[],"source":["### Ex-2-Task-1\n","class CNNModel(nn.Module):\n","    def __init__(self):\n","        \"\"\"\n","        This function initializes the layers for the CNN model\n","        \"\"\"\n","        super(CNNModel, self).__init__()\n","\n","        # parameters for conv layers\n","        filter_dim = 3\n","        in_channels = [3, 16, 32, 32]\n","        out_channels = [16, 32, 32, 64]\n","\n","        # parameters for dense layers\n","        dense_in_features = [4096, 256]\n","        dense_out_features = [256, 10]\n","\n","        # initializing all the layers\n","        self.c1 = Conv2D(in_channels[0], out_channels[0], filter_dim)\n","        self.c2 = Conv2D(in_channels[1], out_channels[1], filter_dim)\n","        self.m1 = MaxPool(2)\n","        self.dropout = nn.Dropout(p=0.25)\n","        self.c3 = Conv2D(in_channels[2], out_channels[2], filter_dim)\n","\n","        self.c4 = None\n","        self.m2 = None\n","        self.d1 = None\n","\n","        # Exercise 2 | Task 1\n","        ### BEGIN SOLUTION\n","        # your code here\n","        raise NotImplementedError\n","        ### END SOLUTION\n","\n","        self.d2 = Dense(dense_in_features[1], dense_out_features[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"04fcbc7851e3331956cf44a65bad4590","grade":false,"grade_id":"cell-f055cfd51ab7d7f6","locked":false,"schema_version":3,"solution":true,"task":false},"tags":["Ex-2-Task-2"],"id":"SA2i6Jvhng4w"},"outputs":[],"source":["### Ex-2-Task-2\n","def forward(self, x):\n","    \"\"\"\n","    This function performs convolutions, relu, max_pooling, dropout, \n","    reshape and dense operations on the input to the model.\n","\n","    Parameters\n","    ------------\n","    x : tensor, float32\n","    Input image to the model\n","\n","    Returns\n","    ------------\n","    x : tensor, float32\n","    output from the last layer\n","\n","    \"\"\"\n","    x = self.c1(x)\n","    x = self.c2(x)\n","    x = self.m1(x)\n","    x = self.dropout(x)\n","\n","    x = self.c3(x)\n","\n","    # Exercise 3 | Task 2\n","    ### BEGIN SOLUTION\n","    # your code here\n","    raise NotImplementedError\n","    ### END SOLUTION\n","\n","    x = self.d2(x)\n","\n","    return x\n","\n","CNNModel.forward = forward\n","model = CNNModel()"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"id":"aaxAvQCYVXpA","nbgrader":{"cell_type":"code","checksum":"abf87d8a95fc8dd632b1bc66d977a8db","grade":true,"grade_id":"cell-17fb45ac2cf30c36","locked":true,"points":2,"schema_version":3,"solution":false},"tags":["Ex-2-Task-1"]},"outputs":[],"source":["# INTENTIONALLY LEFT BLANK"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"id":"KsxadlsLWgQH","nbgrader":{"cell_type":"code","checksum":"fe89967491efbb605b44381808af762e","grade":true,"grade_id":"cell-4e8a6c6a17168215","locked":true,"points":2,"schema_version":3,"solution":false},"tags":["Ex-2-Task-2"]},"outputs":[],"source":["# INTENTIONALLY LEFT BLANK"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WN7R2z3Mg4kb"},"outputs":[],"source":["example = torch.randn((1, 3, 32,32))\n","output = model(example)\n","model"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"bwSUBrgFCtmI","nbgrader":{"cell_type":"markdown","checksum":"55ad29c12da87e7029d46420149794ab","grade":false,"grade_id":"cell-7ca27eebabd983c8","locked":true,"schema_version":3,"solution":false}},"source":["Once we pass the input through the model, we can now check the model summary to visualize all the layers, parameters in each layer and the total number of parameters."]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"lmldwl7gTl33","nbgrader":{"cell_type":"markdown","checksum":"e79f9a4b53eea418038892d96d5e11fb","grade":false,"grade_id":"cell-1ab4cadaa0a5836b","locked":true,"schema_version":3,"solution":false}},"source":["<h2><b>Exercise 3: Implement Cost Function</b></h2>\n","\n","<b>[POINTS: 1]</b>\n","\n","Now, you need to compute the cost using a cost function, to check if your model is actually learning or not.\n","Here we will be creating a function to compute the cross-entropy cost $J$, given the actual and predicted labels. The formula for cross entropy loss is given below: $$-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(A^{[L] (i)}\\right) + (1-y^{(i)})\\log\\left(1- A^{[L](i)}\\right)) $$\n","\n","As for this exercise, you will be directly using a built-in Tensorflow function for the cross entropy loss. \n","\n","<h3><b>Task:</b></h3>\n","<b>[POINTS: 1]</b>\n","\n","(1 line of code)\n","\n","Use the `F.cross_entropy` function to calculate the cross entropy loss between the target and predicted output."]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"id":"q-8Y7jJfi2TP","nbgrader":{"cell_type":"code","checksum":"52481a9102058fdd3d5fb0614f13c06e","grade":false,"grade_id":"cell-cbeb4552dc897a5c","locked":false,"schema_version":3,"solution":true},"tags":["Ex-3-Task-1"]},"outputs":[],"source":["### Ex-3-Task-1\n","def loss(target_y, predicted_y):\n","    \"\"\"\n","    Cross entropy loss between target and predicted value\n","      \n","    Parameters\n","    ----------\n","    target_y: tensor, float32\n","    Target labels\n","    predicted_y: tensor, float32\n","    Prediction of the classes made by model\n","      \n","    Returns\n","    -------\n","    cost: tensor, float32\n","    The average cross-entropy cost of the mini-batch of inputs\n","      \n","    \"\"\"\n","    cost = None\n","    # Exercise 3\n","    ### BEGIN SOLUTION\n","    # your code here\n","    raise NotImplementedError\n","    ### END SOLUTION\n","\n","    return cost"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"id":"dKLJ8fQvqE73","nbgrader":{"cell_type":"code","checksum":"02bab39c1386e620ecfe39ffd9f7713e","grade":true,"grade_id":"cell-c63ba0e2871ab2e1","locked":true,"points":1,"schema_version":3,"solution":false},"tags":["Ex-3-Task-1"]},"outputs":[],"source":["# INTENTIONALLY LEFT BLANK\n","### BEGIN HIDDEN TEST\n","y1 = torch.tensor([1, 0, 1, 0])\n","y2 = torch.tensor([[0.93, 0.07], [0.15, 0.85], [0.3, 0.7], [0.7, 0.3]])\n","assert loss(y1, y2).item() == 0.8355244398117065\n","### END HIDDEN TEST"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"9QJeHnT1TuDb","nbgrader":{"cell_type":"markdown","checksum":"d0b27a9816aac701889c251c7e75f121","grade":false,"grade_id":"cell-d15a28c295ab7cec","locked":true,"schema_version":3,"solution":false}},"source":["<h2><b>Exercise 4: Calculation of Gradients and Optimization</b></h2>\n","\n","<b>[POINTS: 2]</b> \n","\n","In this section, we move to the optimization process. We will be calculating the gradients and use them to update the trainable parameters of the model with the help of an optimizer. \n","We will define a function `train()` which takes four parameters: model, inputs, outputs, and optimizer. It returns the current loss of the model and its predicted output labels.\n","\n","<h3><b>Task:</b></h3>\n","<b>[POINTS: 2]</b> \n","\n","(2 lines of code)\n","\n","Compute gradients with the help GradientTape (for automatic differentiation) and apply the gradients to update the weights of the model using the Adam optimizer set below. \n","\n","Perform backward propagation from the calculated loss and update model parameters using optimizer. Be sure to remove previously calculated gradients.\n","\n","**Hint:**\n","Use backward() method and step() method from loss and optimizer respectively."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GD9myzXl4u7S"},"outputs":[],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","model = model.to(device)\n","\n","LEARNING_RATE = 0.001\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"id":"G7CeaKMxi9Ga","nbgrader":{"cell_type":"code","checksum":"d95c4976fe5e24b1b78738eead8481b4","grade":false,"grade_id":"cell-d284357143e5c125","locked":false,"schema_version":3,"solution":true},"tags":["Ex-4-Task-1"]},"outputs":[],"source":["### Ex-4-Task-1\n","\n","def train(model: nn.Module, inputs, outputs, optimizer: torch.optim.Optimizer):\n","    \"\"\"\n","    A function for training a model which performs both gradient computation \n","    and weight update.\n","    \n","    Parameters\n","    ----------\n","    model: CNNModel\n","    The model for training, should be in train mode.\n","\n","    inputs: tensor\n","    Tensor of features or independent data(samples)\n","\n","    outputs: tensor\n","    Tensor of actual labels or dependent data\n","                   \n","    Returns:\n","    -------\n","    current_loss: tensor, float32\n","    loss of the current training step\n","\n","    y_predicted: tensor, float32\n","    Prediciton by the model at the current training step\n","    \"\"\"\n","\n","    optimizer.zero_grad()\n","   \n","    y_predicted = model(inputs)\n","    y = outputs\n","    current_loss = loss(y, y_predicted)\n","\n","    # Exercise 4 \n","    ### BEGIN SOLUTION\n","    # your code here\n","    raise NotImplementedError\n","    ### END SOLUTION\n","    \n","    return current_loss, y_predicted    "]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"id":"LXK2fAXnjaBf","nbgrader":{"cell_type":"code","checksum":"17dff8ec43bdb1732373cd0417c56bca","grade":true,"grade_id":"cell-bbadd8c67d35979d","locked":true,"points":2,"schema_version":3,"solution":false},"tags":["Ex-4-Task-1"]},"outputs":[],"source":["# INTENTIONALLY LEFT BLANK"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"S8CulOGwUISC","nbgrader":{"cell_type":"markdown","checksum":"d50df54be5fb478cded6c2467f210297","grade":false,"grade_id":"cell-d2de3f95d90b272f","locked":true,"schema_version":3,"solution":false}},"source":["<h2><b>Exercise 5: Training and Evaluation</b></h2>\n","\n","<b>[POINTS: 4]</b>\n","\n","For the final part, you will be training the model on the training dataset. You will be marked on the test accuracy that you receive. Now here, you will perform the training process with the hyperparameters like number of epochs, batch size and learning rate.The records of the training accuracy in each epoch as well as the test accuracy in each epoch are stored in variable named `train_acc_per_epoch` and `test_acc_per_epoch` respectively.\n","\n","To get the feel of how your optimization is working, we have printed the value of total loss and accuracy at each epoch for both the training and test sets. You can tweak the number of epochs, batch size and learning rate to observe the changes in training as well. To start off, you can use the default values set by us."]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"hG11ck13DK0y","nbgrader":{"cell_type":"markdown","checksum":"28c6ef2e4d98ead41cb78a451faf7d86","grade":false,"grade_id":"cell-ea7705b890f1ffd3","locked":true,"schema_version":3,"solution":false}},"source":["**Criteria for the distribution of the marks is:**\n","\n","Level 2 : Test accuracy more than 60 % -> Full marks\n","\n","Level 1 : Test accuracy between 50%-60 % -> 50% marks\n","\n","Accuracy less than 50 % : No marks\n","\n","You have no tasks as such for this section. You can check out the training process and predictions below  by just executing the cells."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P33Aapr8k7H8"},"outputs":[],"source":["batch_size = 128\n","num_epochs = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"id":"Pjr2YFLjk8yu","nbgrader":{"cell_type":"code","checksum":"4029b094e2efeb2c7ba912780b10cc46","grade":false,"grade_id":"cell-518abae3a7f13d42","locked":true,"schema_version":3,"solution":false}},"outputs":[],"source":["# creating dataloader of samples from the dataset\n","train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"id":"-rPmck5Rk-jK","nbgrader":{"cell_type":"code","checksum":"9b99707c08259ed09c09ae7e17afa439","grade":false,"grade_id":"cell-4fc9b9ebacaa4b27","locked":false,"schema_version":3,"solution":true,"task":false},"tags":["Ex-5-Task-1"]},"outputs":[],"source":["### Ex-5-Task-1\n","\n","\n","\n","train_acc_per_epoch = []\n","test_acc_per_epoch = []\n","\n","print(\"Training\")\n","\n","for i in range(num_epochs):\n","    train_loss = []\n","    train_acc = []\n","    model.train()\n","    for num, (x_batch, y_batch) in enumerate(train_loader):\n","        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","        losses, pred = train(model, x_batch, y_batch, optimizer) \n","        train_loss.append(losses.item())\n","        train_acc.append((y_batch == pred.argmax(dim=-1)).float().mean().item())\n","    \n","    test_loss = []\n","    test_acc = []\n","    model.eval()\n","    with torch.no_grad():\n","        for x_batch, y_batch in test_loader:\n","            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","            test_pred = model(x_batch)\n","            test_loss.append(loss(y_batch, test_pred).item())\n","            test_acc.append((y_batch == test_pred.argmax(dim=-1)).float().mean().item())\n","    \n","    print('\\nEpoch: {}\\tTrain Loss: {}\\tTrain Accuracy: {}\\n\\t\\tTest Loss: \\\n","    {}\\tTest Accuracy: {}\\n'.format(\n","         i+1, np.mean(train_loss), np.mean(train_acc), np.mean(test_loss), \n","         np.mean(test_acc)\n","    ))\n","\n","    # tracking accuracy in each epoch for plot\n","    train_acc_per_epoch.append(np.mean(train_acc))\n","    test_acc_per_epoch.append(np.mean(test_acc))\n","\n","# To save the trained model for later use\n","export_file = 'cifar.pth'\n","torch.save(model, export_file)\n","\n","with open(\"test_acc.txt\", \"wb\") as fp:\n","    pickle.dump(test_acc, fp)\n","\n","#### UPLOAD test_acc.txt ALONG WITH YOUR SUBMISSION"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"_OZyacWj9yPN","nbgrader":{"cell_type":"markdown","checksum":"490d3ef69c354be380378be9127281a8","grade":false,"grade_id":"cell-cec0c328d70d7dc4","locked":true,"schema_version":3,"solution":false}},"source":["Alright! You have completed all your tasks. Now, you can check your training and validation accuracy here. It's time for us to evaluate the model and give you marks on the basis of the accuracy your model achieves on the test set. For a visualization of your accuracy, you can checkout the plot below."]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"id":"ypctu_cYISpw","nbgrader":{"cell_type":"code","checksum":"1f12d9f83496da48d73d72ce05f01976","grade":false,"grade_id":"cell-dd3be1a1dbff18d1","locked":false,"schema_version":3,"solution":true,"task":false},"tags":["Ex-5-Task-2"]},"outputs":[],"source":["### Ex-5-Task-2\n","\n","\n","plt.plot(range(0,num_epochs), train_acc_per_epoch, 'b', label='Training Accuracy')\n","plt.plot(range(0,num_epochs), test_acc_per_epoch, 'r', label='Test Accuracy')\n","plt.title('Training and Test Accuracy')\n","plt.xlabel('Epochs ',fontsize=16)\n","plt.ylabel('Loss',fontsize=16)\n","plt.legend()\n","plt.figure()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"id":"PdL5f1uN9TBL","nbgrader":{"cell_type":"code","checksum":"f559980ecf26f4308752e1e1c1127599","grade":true,"grade_id":"cell-2e9073662377009c","locked":true,"points":2,"schema_version":3,"solution":false},"tags":["Ex-5-Task-1"]},"outputs":[],"source":["# INTENTIONALLY LEFT BLANK"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"id":"hDmfeIcP_0kb","nbgrader":{"cell_type":"code","checksum":"0261fa564533d1fc68161acb56e85051","grade":true,"grade_id":"cell-979dac0cdcfb0870","locked":true,"points":2,"schema_version":3,"solution":false},"tags":["Ex-5-Task-2"]},"outputs":[],"source":["# INTENTIONALLY LEFT BLANK"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"CAYN6jnhMD6M","nbgrader":{"cell_type":"markdown","checksum":"66e1824ecfce60dff7a23390c672c97f","grade":false,"grade_id":"cell-b1872ba04414757b","locked":true,"schema_version":3,"solution":false}},"source":["<h2><b>Predicting the labels for test_set</b></h2>\n","\n","Now that you have checked the model performance on both the train and test set, in this section you'll be even more clear with what the model has predicted for your test data. We create a `predict` function that passes the inputs through the model and print the predicted labels. We then print the actual and predicted labels for two samples of the test_dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"id":"EhMLfTe4Iyzt","nbgrader":{"cell_type":"code","checksum":"6f23c394118afdf7cad5563e00821bb9","grade":false,"grade_id":"cell-58b0d50e55bd8ae9","locked":true,"schema_version":3,"solution":false}},"outputs":[],"source":["def predict(inputs):\n","    \"\"\"\n","    This function predicts the predicted outputs for the given test input sample\n","\n","    Parameters\n","    ------------\n","    inputs : tensor, float32\n","    test input sample\n","\n","    Returns:\n","    -------------\n","    predicted: tensor, float32\n","    Predicitons for each class by the model \n","    \"\"\"\n","    export_file = 'cifar.pth'\n","    cifar_model = torch.load(export_file).to(device)\n","    predicted = cifar_model(inputs.to(device))\n","    return predicted"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ggCwIyl1I2MV"},"outputs":[],"source":["for sample, label in test_loader:\n","    pred = predict(sample)\n","    first_five_pred = pred[0:5]\n","    print(\"Predicted labels for first five samples of the first batch:\",torch.argmax(first_five_pred, dim=-1))\n","    print(\"Actual labels for first five samples of the first batch:\", label[0:5])\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hBfo_CcDrTEI"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"CNN_L2_Assignment(PyTorch).ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":0}