{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "_Z-N7Ylp0-Gi",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b0ce13b5ea561fdc64db96b3016ced66",
          "grade": false,
          "grade_id": "cell-5c7c35e5db56651f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# Machine Translation using Sequence to Sequence LSTM networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "7BEzkQrJ0-Gn",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c09f58dd19c22fd8c14a82ecfdb3ad36",
          "grade": false,
          "grade_id": "cell-86a6d09c34d33f25",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Machine translation refers to the use of machines or software to translate text to speech or speech from one language to another language.\n",
        "\n",
        "In this assignment we will work out the demonstration of how we can apply the LSTM networks to translate speech from one language to another.\n",
        "\n",
        "We will be translating sequences from English to Chinese."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "pGuEgkXT0-Gn",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "aaf14ad60b6057ae5ef2f283fae3a801",
          "grade": false,
          "grade_id": "cell-e29498e719ab95c6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Datasets\n",
        "We will be using this dataset. https://www.manythings.org/anki/cmn-eng.zip.\n",
        "\n",
        "Few samples of the dataset looks as follows:\n",
        "\n",
        "**$ENGLISH \\hspace{10mm} CHINESE$**\n",
        "\n",
        "$Go. \\hspace{30mm} 走 $\n",
        "\n",
        "$Run! \\hspace{30mm} 跑!$\n",
        "\n",
        "$Fire! \\hspace{30mm} A火！$\n",
        "\n",
        "$Help! \\hspace{30mm} 救命!$\n",
        "\n",
        "$Jump. \\hspace{30mm} 跳.$\n",
        "\n",
        "$Stop! \\hspace{30mm} 停止!$\n",
        "\n",
        "We can see that on the left column, we have a list of english sequences like, GO, RUN, FIRE, HELP, etc and on the right we have their respective CHINESE tranlsations.\n",
        "\n",
        "Here, the input to the model will be the list of English sentences and the target will be the list of Chinese translations.\n",
        "\n",
        "Here in the dataset,\n",
        "\n",
        "We will follow the following steps duing the machine translation:\n",
        "\n",
        "1. Preprocess the training sequenes\n",
        "2. Develop sequence to sequence LSTM model\n",
        "3. Train LSTM model\n",
        "4. Evalute model by testing the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "AxGshOMk6_n9",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "7fc6f0c2167c4587dc68f0dcbeeac76e",
          "grade": false,
          "grade_id": "cell-322635f771076732",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ZCo5hAFPw6MR",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "453a2c02cdbbb02cb0046e352998d837",
          "grade": false,
          "grade_id": "cell-92d78258255f0c3e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "UrdGrSJoxC3o",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fe69062cf677017d2c47b789df0f9a32",
          "grade": false,
          "grade_id": "cell-64ea11783dd9398f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83dfc3bc-a5c1-4500-93f6-c02ca8a627b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "vU1L7fAckbxe",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ca7a41a47f2a4f4c921145cb562375bc",
          "grade": false,
          "grade_id": "cell-949aff3298d2f0f0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Let's read the dataset from the directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "mQgGzF147E-j",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "56425b9d799dd5ce1268301ab7c58c7e",
          "grade": false,
          "grade_id": "cell-f81b84edf1b80a87",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Reading the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "9VCyVeGew6MT",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fcc930cecb546092836f694d5b4ce982",
          "grade": false,
          "grade_id": "cell-3cdcf87702aba82a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "5bc1b75e-1cb7-4d50-c8b7-ca0b1a0435ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     eng  \\\n",
              "0                                                    Hi.   \n",
              "1                                                    Hi.   \n",
              "2                                                   Run.   \n",
              "3                                                  Wait!   \n",
              "4                                                  Wait!   \n",
              "...                                                  ...   \n",
              "24021  Tom didn't know how to translate the word \"com...   \n",
              "24022  Even now, I occasionally think I'd like to see...   \n",
              "24023  It's very easy to sound natural in your own na...   \n",
              "24024  I got fired from the company, but since I have...   \n",
              "24025  If a person has not had a chance to acquire hi...   \n",
              "\n",
              "                                               chin  \\\n",
              "0                                                嗨。   \n",
              "1                                               你好。   \n",
              "2                                             你用跑的。   \n",
              "3                                               等等！   \n",
              "4                                              等一下！   \n",
              "...                                             ...   \n",
              "24021               汤姆不知如何翻译“计算机”一词，因为同他谈话的人从未见过一台。   \n",
              "24022            即使是现在，我偶尔还是想见到你。不是今天的你，而是我记忆中曾经的你。   \n",
              "24023                  你很容易把母语说得通顺流畅，却很容易把非母语说得不自然。   \n",
              "24024              虽然我被公司解雇了，但是我还有点存款，所以目前不用担心生计问题。   \n",
              "24025  如果一個人在成人前沒有機會習得目標語言，他對該語言的認識達到母語者程度的機會是相當小的。   \n",
              "\n",
              "                                                    info  \n",
              "0      CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
              "1      CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
              "2      CC-BY 2.0 (France) Attribution: tatoeba.org #4...  \n",
              "3      CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
              "4      CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
              "...                                                  ...  \n",
              "24021  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
              "24022  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
              "24023  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
              "24024  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
              "24025  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
              "\n",
              "[24026 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2b50e29-a507-468e-82f3-f03b269ce035\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>chin</th>\n",
              "      <th>info</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>嗨。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>你好。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run.</td>\n",
              "      <td>你用跑的。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wait!</td>\n",
              "      <td>等等！</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Wait!</td>\n",
              "      <td>等一下！</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24021</th>\n",
              "      <td>Tom didn't know how to translate the word \"com...</td>\n",
              "      <td>汤姆不知如何翻译“计算机”一词，因为同他谈话的人从未见过一台。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24022</th>\n",
              "      <td>Even now, I occasionally think I'd like to see...</td>\n",
              "      <td>即使是现在，我偶尔还是想见到你。不是今天的你，而是我记忆中曾经的你。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24023</th>\n",
              "      <td>It's very easy to sound natural in your own na...</td>\n",
              "      <td>你很容易把母语说得通顺流畅，却很容易把非母语说得不自然。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24024</th>\n",
              "      <td>I got fired from the company, but since I have...</td>\n",
              "      <td>虽然我被公司解雇了，但是我还有点存款，所以目前不用担心生计问题。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24025</th>\n",
              "      <td>If a person has not had a chance to acquire hi...</td>\n",
              "      <td>如果一個人在成人前沒有機會習得目標語言，他對該語言的認識達到母語者程度的機會是相當小的。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24026 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2b50e29-a507-468e-82f3-f03b269ce035')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f2b50e29-a507-468e-82f3-f03b269ce035 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f2b50e29-a507-468e-82f3-f03b269ce035');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "lines = pd.read_table('/content/drive/My Drive/Colab Notebooks/ML /cmn.txt', names=['eng', 'chin', 'info'])\n",
        "#lines = pd.read_table('./cmn.txt', names=['eng', 'chin', 'info'])\n",
        "lines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "dvqLeT1hkS_1",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "4602bba070f00465a7f411ce333ea381",
          "grade": false,
          "grade_id": "cell-109bf8e6353d477b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "We are concerned with only english to chinese translation, so we choose these two columns.\n",
        "### Exercise 1\n",
        "#### Task 1\n",
        "<b><div style=\"text-align: right\">[POINTS: 2]</div></b>\n",
        "* Select the English and Chinese translation columns\n",
        "* Select the first 10,000 samples and store it on `lines` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "deletable": false,
        "id": "txXegvQykUFr",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "11a7c082ad344bbf53fbc79a134ca6a5",
          "grade": false,
          "grade_id": "cell-8d554e7a8fae2b5f",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "tags": [
          "Ex-1-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "### Ex-1-Task-1\n",
        "# lines = None\n",
        "\n",
        "# Select `eng` and `chin` columns from the table\n",
        "# take only first 10,000 samples to train\n",
        "\n",
        "### BEGIN SOLUTION\n",
        "# your code here\n",
        "lines  = lines.iloc[:, :2]\n",
        "lines = lines.iloc[:10000, :]\n",
        "\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "zgYFaXI_0-Gr",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a3d1a3f4c8d47e319282102289d91b29",
          "grade": true,
          "grade_id": "cell-cc75ee800e422bec",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false
        },
        "tags": [
          "Ex-1-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "assert lines is not None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Kh7IpJH-w6MT",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5bd3454c7013d5e967f924cdf40bec69",
          "grade": false,
          "grade_id": "cell-c1a557d4e1f790be",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a903c030-d5d1-4962-ca1d-1b7583a8b5d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "# displaying shape of the training set\n",
        "lines.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "qJqfTx_S7MBm",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "6a3fefeb3dbff03a8151d1ceafe32a43",
          "grade": false,
          "grade_id": "cell-6f124aca6532ebf9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Data-Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "1p_OI3gCm1nY",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "69ae6492cb816a54dd76e1158feb7ff8",
          "grade": false,
          "grade_id": "cell-12b91bc6ebf516bb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "We will follow the following preprocessing steps in order to clean the dataset and fit into model training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "9OavBlnl0-Gs",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d0e3ec6a0dcb40c939ed480e66929e06",
          "grade": false,
          "grade_id": "cell-55d8579a96347262",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Lowercasing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ayVesOcK0-Gs",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a573be3cc12561afab4c01b19ce01795",
          "grade": false,
          "grade_id": "cell-818a7628e07222c7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# lowercase inputs on the columns \n",
        "lines.eng = lines.eng.apply(lambda x: x.lower())\n",
        "lines.chin = lines.chin.apply(lambda x: x.lower())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ePdmVLLlw6MU",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "82f8bf7c2439c84eb248d1b09d073edf",
          "grade": false,
          "grade_id": "cell-ae96a6b81a1185d7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Exercise 2\n",
        "\n",
        "Above, we just performed lowercasing of the input samples. Lowercasing is the first operation we performed. Now, we will perform other operations like: `Removing Quotes`, `Removing Special Characters`, `Removing Uneven Spaces`, `Adding <START> and <END> tokens`, etc. Perform similar implementations like that mentioned above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "d-vf6AbR0-Gs",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "068af81cad8ab07cbbceb9a3cbccd94d",
          "grade": false,
          "grade_id": "cell-88c2f1ffb428de99",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Removing Quotes\n",
        "<b><div style=\"text-align: right\">[POINTS: 3]</div></b>\n",
        "#### Task 1\n",
        "<b><div style=\"text-align: right\">[POINTS: 1]</div></b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "deletable": false,
        "id": "cnxN3CNhw6MU",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "24f6e9de968fb417c8bddc9654cbe58b",
          "grade": false,
          "grade_id": "cell-166a4b682ff40791",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "tags": [
          "Ex-2-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "### Ex-2-Task-1\n",
        "\n",
        "# remove all the quotes \"'\" from the columns\n",
        "\n",
        "# lines.eng = None\n",
        "# lines.chin = None\n",
        "\n",
        "# Exercise 2 | Task 1\n",
        "### BEGIN SOLUTION\n",
        "# your code here\n",
        "lines.eng = lines.eng.apply(lambda x : x.replace(\"'\", \"\"))\n",
        "lines.chin = lines.chin.apply(lambda x : x.replace(\"'\", \"\"))\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "EFKIDmSg0-Gt",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8533a681c6890484e1bd4547c9a4380a",
          "grade": true,
          "grade_id": "cell-71fafecfa7e89a02",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "tags": [
          "Ex-2-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "assert lines.eng is not None\n",
        "assert lines.chin is not None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "dQPsCJ-t0-Gt",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "fe5f76d98ab6f1851b1222a619d68c5c",
          "grade": false,
          "grade_id": "cell-17278651b7e58ab4",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Removing Special Characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "3c7SFZZJw6MU",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1500be7e854dc4d11e9ab8ce40c44f4a",
          "grade": false,
          "grade_id": "cell-57bd2575631fb4c8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Set of all special characters\n",
        "sets_of_punctuations = set(string.punctuation)\n",
        "\n",
        "# Removing sets of all special characters from the inputs\n",
        "lines.eng = lines.eng.apply(lambda x: ''.join(char for char in x if char not in sets_of_punctuations))\n",
        "lines.chin = lines.chin.apply(lambda x: ''.join(char for char in x if char not in sets_of_punctuations))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "zdfLmsrY0-Gt",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "7e6b1f4a051d2cb789b504fb6beb0685",
          "grade": false,
          "grade_id": "cell-5ae1b11f41d71b27",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Removing Uneven Spaces\n",
        "#### Task 2\n",
        "<b><div style=\"text-align: right\">[POINTS: 1]</div></b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "deletable": false,
        "id": "0NJg9Wtxw6MV",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6262580c52c9c0d41e3f48056d849424",
          "grade": false,
          "grade_id": "cell-b5bd2c20a73d1679",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "tags": [
          "Ex-2-Task-2"
        ]
      },
      "outputs": [],
      "source": [
        "### Ex-2-Task-2\n",
        "# lines.eng = None\n",
        "# lines.chin = None\n",
        "\n",
        "# There may be uneven spaces in the inputs\n",
        "# We have to remove the extra spaces too\n",
        "\n",
        "# Exercise 2 | Task 2\n",
        "### BEGIN SOLUTION\n",
        "# your code here\n",
        "lines.eng = lines.eng.apply(lambda x : \" \".join(x.strip().split()))\n",
        "lines.chin = lines.chin.apply(lambda x : \" \".join(x.strip().split()))\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "M4dMDkYn0-Gu",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9274c3da54ce529a0a48fd322b407e24",
          "grade": true,
          "grade_id": "cell-557c50952c53e7ed",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "tags": [
          "Ex-2-Task-2"
        ]
      },
      "outputs": [],
      "source": [
        "assert lines.eng is not None\n",
        "assert lines.chin is not None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "nf_nMZp00-Gu",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "50e043f4e44d400cb3a775b965b6b665",
          "grade": false,
          "grade_id": "cell-03607f2602068f04",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Adding `<START>` and `<END>` Tokens\n",
        "E.g.\n",
        "'Hi' = '`<START>` Hi `<END>`'\n",
        "#### Task 3\n",
        "<b><div style=\"text-align: right\">[POINTS: 1]</div></b>\n",
        "We will perform this operations over Chinese column samples only because we are converting English sequences to chinese only for now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "deletable": false,
        "id": "24kKSFCjw6MW",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d8df2bf22b3b379332eeeebc57bd287e",
          "grade": false,
          "grade_id": "cell-ad1abc3f8ffea62a",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "tags": [
          "Ex-2-Task-3"
        ]
      },
      "outputs": [],
      "source": [
        "### Ex-2-Task-3\n",
        "# lines.chin = None\n",
        "\n",
        "# Adding <START> and <END> tokens with trailing spaces\n",
        "\n",
        "# Exercise 2 | Task 3\n",
        "### BEGIN SOLUTION\n",
        "# your code here\n",
        "lines.chin = lines.chin.apply(lambda x : \"<START> {} <END>\".format(x))\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "PJA33kQZ0-Gu",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9a0a377fd98f6659655db1b424338212",
          "grade": true,
          "grade_id": "cell-fd254802897335ea",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "tags": [
          "Ex-2-Task-3"
        ]
      },
      "outputs": [],
      "source": [
        "assert lines.chin is not None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ojnbyezHqUaG",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "86a9ff8785d8ef6fb2437aae08cf171b",
          "grade": false,
          "grade_id": "cell-d4bdec9ded84970b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Now, our next task is to create a list of vocabularies of English and Chinese Inputs.\n",
        "\n",
        "Following code will tokenize the words present in the English and Chinese dataset that we use to train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "vBibz4Gn666N",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8153db3e15c212af999f9d8622e21efc",
          "grade": false,
          "grade_id": "cell-fd22ab95a6103221",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Tokenizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "5GtJWhtG7UiM",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "31a8e3c3129bf64cf3af93c2d1e27ca2",
          "grade": false,
          "grade_id": "cell-3c2d3a9eb7586ce1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Tokenizing the English and the Chinese words in to set `all_english_vocabs` and `all_chinese_vocabs`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "dY-j6xPpqdPT",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "eb09fd0d0113e567e720dff6a2d57257",
          "grade": false,
          "grade_id": "cell-cdb536778da0a35b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Collect English Vocabs\n",
        "all_english_vocabs = set()\n",
        "for english in lines.eng:\n",
        "    words = english.split()\n",
        "    for word in words:\n",
        "        if word not in all_english_vocabs:\n",
        "            all_english_vocabs.add(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "UJGtunRdtPdX",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2c81f85aa3a4cd2c1d99800f0a4bfe4b",
          "grade": false,
          "grade_id": "cell-9573d55a6cc7a79a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Collect Chinese Vocabs\n",
        "all_chinese_vocabs = set()\n",
        "for chinese in lines.chin:\n",
        "    words = chinese.split()\n",
        "    for word in words:\n",
        "        if word not in all_chinese_vocabs:\n",
        "            all_chinese_vocabs.add(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "AqQxd93At8Y_",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "aaa117a1a9ef6101a6dcbb4e172ff64c",
          "grade": false,
          "grade_id": "cell-2b285bbaaf0bb29c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Let's implement the following codes to find the maximum sequence length of input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ApMcilUdw6MX",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8406af3f5b0446b0750be37157760ddf",
          "grade": false,
          "grade_id": "cell-54947cadd4bdeb58",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee663e0f-f716-4414-b2b9-48ef4d803512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ],
      "source": [
        "# Max Length of input sequence\n",
        "sequence_length = []\n",
        "for line in lines.eng:\n",
        "    sequence_length.append(len(line.split(' ')))\n",
        "max_length_inp = np.max(sequence_length)\n",
        "print(max_length_inp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "5r8H-xriw6MX",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bb4f46c3196a78a0d7abba9159251659",
          "grade": false,
          "grade_id": "cell-389126c8d63c4124",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c70aefc4-482f-4e94-d11e-fe6ab3d691af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ],
      "source": [
        "# Max Length of target sequence\n",
        "sequence_length = []\n",
        "for line in lines.chin:\n",
        "    sequence_length.append(len(line.split(' ')))\n",
        "max_length_targ = np.max(sequence_length)\n",
        "max_length_targ"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2IttlBoSaoL7"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "z2ID7e3a0-Gw",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "94d6bac02b2788a4fe011e9d500c21a4",
          "grade": false,
          "grade_id": "cell-8f6c8ab252764056",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "With this, we can see that the maximum input sequence is 8 and the maximum target sequence is 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "scApqmY00-Gw",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "40d5094d209e6b7975b5e3eca73db2a9",
          "grade": false,
          "grade_id": "cell-05bfb2e9b479f1e7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Exercise 3\n",
        "<b><div style=\"text-align: right\">[POINTS: 2]</div></b>\n",
        "#### Task 1\n",
        "<b><div style=\"text-align: right\">[POINTS: 1]</div></b>\n",
        "Sort and store the tokenized English and Chinese words on the variables `input_words` and `target_words`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "deletable": false,
        "id": "mTOotq_Iw6MY",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9078779aa366ba1983eafb52d994367c",
          "grade": false,
          "grade_id": "cell-a233cc05cff264ec",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "tags": [
          "Ex-3-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "### Ex-3-Task-1\n",
        "\n",
        "# input_words = None\n",
        "# target_words = None\n",
        "\n",
        "# Sorting and Storing the tokens of English and Chinese words\n",
        "\n",
        "# Exercise 3\n",
        "### BEGIN SOLUTION\n",
        "# your code here\n",
        "input_words = sorted(all_english_vocabs)\n",
        "target_words = sorted(all_chinese_vocabs) \n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "e9MTr3c-0-Gx",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7dc42d6bc240ed9b4598a698272bdbae",
          "grade": true,
          "grade_id": "cell-15b8c56f73279370",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "tags": [
          "Ex-3-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "assert input_words is not None\n",
        "assert target_words is not None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlODcVXyAo98"
      },
      "source": [
        "#### Task 2\n",
        "<b><div style=\"text-align: right\">[POINTS: 1]</div></b>\n",
        "Since, we are performing Machine translation, we have an encoder and decoder kind of architecture. We will have the encoder architecture as following:\n",
        "\n",
        "<div align=\"center\">\n",
        "<figure>\n",
        "<img src=\"https://doc.google.com/a/fusemachines.com/uc?id=1voHxN0hllGSLfyPJSy6tI_hzTNO6hHRl\" >\n",
        "<figcaption>Figure 1. Machine Translation\n",
        "</figcaption>\n",
        "</figure>\n",
        "</div>\n",
        "\n",
        "Here, the green denoted LSTM cells represent the encoder part and the red LSTM cells represent the decoder part of a Machine Translation network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "deletable": false,
        "id": "ZkXtWETvAnZ5",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c9db575d6fd33f6657706244f3d78c37",
          "grade": false,
          "grade_id": "cell-d21094fc3564a7c2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": [
          "Ex-3-Task-2"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09e5daee-69cd-4763-9c26-b6ca1c2a279b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3380 9023\n"
          ]
        }
      ],
      "source": [
        "### Ex-3-Task-2\n",
        "# counting the total tokens of English and Chinese words\n",
        "num_encoder_tokens = None\n",
        "num_decoder_tokens = None\n",
        "### BEGIN SOLUTION\n",
        "# your code here\n",
        "num_encoder_tokens = len(input_words)\n",
        "num_decoder_tokens = len(target_words)\n",
        "### END SOLUTION\n",
        "print(num_encoder_tokens, num_decoder_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "idi_diAO0-Gx",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ede6a6c888773ecf37e16e8e132e6643",
          "grade": true,
          "grade_id": "cell-cd48ce4fc6942143",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "tags": [
          "Ex-3-Task-2"
        ]
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "HZSC0tsow6MY",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "be0bb5f1bd433ae49ce0865a36b5d4a3",
          "grade": false,
          "grade_id": "cell-040c48796e20c48e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e852466-68b0-4825-cb6b-32b4bf1f045f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3381, 9024)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ],
      "source": [
        "# For zero padding we add one extra token\n",
        "num_decoder_tokens += 1\n",
        "num_encoder_tokens += 1\n",
        "num_encoder_tokens, num_decoder_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "MYPMZqntw6MZ",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7f9b24c88907af9d6fc4abfd0f2d3b26",
          "grade": false,
          "grade_id": "cell-df7be80213612242",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# compute and store the tokens with index in dictionary as word, index format\n",
        "input_token_index = dict([(word, i + 1) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict([(word, i + 1) for i, word in enumerate(target_words)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ofUESFVWw6MZ",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fe1c30203bafa9868d0d233747ebf40a",
          "grade": false,
          "grade_id": "cell-85cd917cd9596b95",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# compute and store the tokens with index in dictionary as index, word format\n",
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "A-jl8mSpw6MZ",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7f4b730ef6492fbd05ede8bffededdea",
          "grade": false,
          "grade_id": "cell-75e847bed23fd5e8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b2d712e6-519e-4080-c900-864f2f1abb94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            eng                     chin\n",
              "5110      where are your things   <START> 你的東西在哪裡？ <END>\n",
              "595                 its so hard       <START> 太难了。 <END>\n",
              "8854  ill send a message to tom  <START> 我会给汤姆发信息。 <END>\n",
              "6713    you should study harder  <START> 你應該更努力學習。 <END>\n",
              "4862      please deal the cards     <START> 請發一下牌。 <END>"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1deb9393-2799-4ced-b435-694e5ac0b987\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>chin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5110</th>\n",
              "      <td>where are your things</td>\n",
              "      <td>&lt;START&gt; 你的東西在哪裡？ &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>595</th>\n",
              "      <td>its so hard</td>\n",
              "      <td>&lt;START&gt; 太难了。 &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8854</th>\n",
              "      <td>ill send a message to tom</td>\n",
              "      <td>&lt;START&gt; 我会给汤姆发信息。 &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6713</th>\n",
              "      <td>you should study harder</td>\n",
              "      <td>&lt;START&gt; 你應該更努力學習。 &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4862</th>\n",
              "      <td>please deal the cards</td>\n",
              "      <td>&lt;START&gt; 請發一下牌。 &lt;END&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1deb9393-2799-4ced-b435-694e5ac0b987')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1deb9393-2799-4ced-b435-694e5ac0b987 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1deb9393-2799-4ced-b435-694e5ac0b987');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ],
      "source": [
        "# shuffling the lines to make better predictions\n",
        "lines = shuffle(lines)\n",
        "lines.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ciFxeS0l0-Gy",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e855f52ea26ed6a78b5271614a523804",
          "grade": false,
          "grade_id": "cell-4874858156792ac3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "U8-wDveew6Ma",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a7eedfd692c48276f98708a8a8409bcd",
          "grade": false,
          "grade_id": "cell-711ad7496e8d5a8c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e0c3b97-7996-4dc5-e420-51a84c78ee8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9000,), (1000,))"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ],
      "source": [
        "# Train - Test Split\n",
        "X, y = lines.eng, lines.chin\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "zSVXqHNaLirV",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "7857b81bc963cfe85ff7a67874257c74",
          "grade": false,
          "grade_id": "cell-9456558d54c0d0ea",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Following code is to generate batch of training and testing data. If you are interested in the code you can go line by line and explore the details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "kM-5q9lbw6Ma",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d776a860adbff380724704f73503def3",
          "grade": false,
          "grade_id": "cell-b1894cc022235615",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
        "    '''Function to generate a batch of data '''\n",
        "    for j in range(0, len(X), batch_size):\n",
        "        encoder_input_data = np.zeros((max_length_inp, batch_size),dtype='float32')\n",
        "        decoder_input_data = np.zeros((max_length_targ, batch_size),dtype='float32')\n",
        "        decoder_target_data = np.zeros((max_length_targ, batch_size ,num_decoder_tokens),dtype='float32')\n",
        "        for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "            for t, word in enumerate(input_text.split()):\n",
        "                encoder_input_data[t, i] = input_token_index[word] # encoder input seq\n",
        "            for t, word in enumerate(target_text.split()):\n",
        "                if t<len(target_text.split())-1:\n",
        "                    decoder_input_data[t, i] = target_token_index[word] # decoder input seq\n",
        "                if t>0:\n",
        "                    # decoder target sequence (one hot encoded)\n",
        "                    # does not include the START_ token\n",
        "                    # Offset by one timestep\n",
        "                    decoder_target_data[t-1, i , target_token_index[word]] = 1.\n",
        "        yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "VrCmUOPX0dsn",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "108ad531aae4affa988fcf9dbb1216f5",
          "grade": false,
          "grade_id": "cell-5ad4b7a3cc4da9e0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Input to the Encoder\n",
        "encoder_input_data = np.zeros((len(lines.eng), 9),dtype='float32')\n",
        "\n",
        "# output from the encoder or input to the decoder \n",
        "decoder_input_data = np.zeros((len(lines.chin), 5),dtype='float32')\n",
        "\n",
        "# output by the decoder\n",
        "decoder_target_data = np.zeros((len(lines.chin), 5, num_decoder_tokens),dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "z3QkOfY70hQK",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8dd8a7bcec06c4a8c969cf1ef6c956b0",
          "grade": false,
          "grade_id": "cell-3c9e2cbc956e1e63",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(lines.eng, lines.chin)):\n",
        "    for t, word in enumerate(input_text.split()):\n",
        "        encoder_input_data[i, t] = input_token_index[word]\n",
        "    for t, word in enumerate(target_text.split()):\n",
        "        decoder_input_data[i, t] = target_token_index[word]\n",
        "        if t > 0:\n",
        "            # decoder target data is ahead of decoder input by one timestep\n",
        "            decoder_target_data[i, t - 1, target_token_index[word]] = 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "aknXbSOLw6Mb",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d1acb35327047493c41527dbd89cd048",
          "grade": false,
          "grade_id": "cell-dbc8da1b20dbba17",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Encoder - Decoder Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "7Wd_xqIbw6Mb",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "eab08df97a955b75b73b334158d24f58",
          "grade": false,
          "grade_id": "cell-6e9227c55dc44051",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "latent_dim = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "BSPvU8Bn0-G0",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0d20248101d130edfd111600d207cd56",
          "grade": false,
          "grade_id": "cell-906a013f79181247",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Exercise 4\n",
        "<b><div style=\"text-align: right\">[POINTS: 4]</div></b>\n",
        "#### Task 1\n",
        "<b><div style=\"text-align: right\">[POINTS: 1]</div></b>\n",
        "Store the hidden state and context vector as a result of encoder outputs on variable `encoder_states`.\n",
        "\n",
        "Store in the form of [__hiddenstate__, __contextstate__]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "deletable": false,
        "id": "i5U5W2T9f7Qk",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "63deee770ecdaabe4190ed7e5abe4859",
          "grade": false,
          "grade_id": "cell-5375e524cb9be57b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": [
          "Ex-4-Task-1"
        ]
      },
      "outputs": [],
      "source": [
        "### Ex-4-Task-1\n",
        "# encoder_states = None\n",
        "\n",
        "# Encoder Architecture\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.input_size = input_size\n",
        "\n",
        "        self.embedding_size = embedding_size\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n",
        "\n",
        "        self.LSTM = nn.LSTM(self.embedding_size, self.hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedding = self.embedding(x)\n",
        "        outputs, (hidden_state, cell_state) = self.LSTM(embedding)\n",
        "        \n",
        "        ### BEGIN SOLUTION\n",
        "        # your code here\n",
        "        encoder_states = (hidden_state, cell_state)\n",
        "        ### END SOLUTION\n",
        "        return encoder_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2aa9b3af095f8429833dca9530395f81",
          "grade": true,
          "grade_id": "cell-71c476202d589f78",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": [
          "Ex-4-Task-1"
        ],
        "id": "sk67U0fRx212"
      },
      "outputs": [],
      "source": [
        "# Intentionally left blank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "-miqEPX4f7Ql",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "78b937a268a0f394a91de96f76b3a5e9",
          "grade": false,
          "grade_id": "cell-ddac4c4be3f9b645",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6f3d950-2efd-4adb-a028-ddb57339b4d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder(\n",
            "  (embedding): Embedding(3381, 50)\n",
            "  (LSTM): LSTM(50, 50)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "encoder = Encoder(num_encoder_tokens, latent_dim, latent_dim)\n",
        "print(encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "jwgWEUvqf7Qm",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3763687430eae58b6cbbcb7e65d2c712",
          "grade": false,
          "grade_id": "cell-57a28a9db81414dd",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        # Size of the one hot vectors that will be the input to the decoder\n",
        "        self.input_size = input_size\n",
        "\n",
        "        # Output size of the word embedding NN\n",
        "        self.embedding_size = embedding_size\n",
        "\n",
        "        # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Size of the one hot vectors that will be the output of the decoder\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n",
        "        self.LSTM = nn.LSTM(self.embedding_size, hidden_size)\n",
        "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, x, enc_states):\n",
        "        x = x.unsqueeze(0)\n",
        "        embedding = self.embedding(x)\n",
        "\n",
        "        # (passing encoder's hs, cs - context vectors)\n",
        "        outputs, (hidden_state, cell_state) = self.LSTM(embedding, enc_states)\n",
        "\n",
        "        predictions = self.fc(outputs)\n",
        "\n",
        "        predictions = predictions.squeeze(0)\n",
        "\n",
        "        decoder_states = (hidden_state, cell_state)\n",
        "\n",
        "        return predictions, decoder_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "zuqq79h6f7Qm",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f14fa8d3ff8a10b6287be85df6c77281",
          "grade": false,
          "grade_id": "cell-5f7f0bed03f209a8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0133fa97-548a-4c97-e5ad-c6753edef3dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder(\n",
            "  (embedding): Embedding(9024, 50)\n",
            "  (LSTM): LSTM(50, 50)\n",
            "  (fc): Linear(in_features=50, out_features=9024, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "decoder = Decoder(num_decoder_tokens, latent_dim, latent_dim, num_decoder_tokens)\n",
        "print(decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ycS6r5fkf7Qm",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "212805f25732ea0776a6ce3bd0a57458",
          "grade": false,
          "grade_id": "cell-c8fc9c2ef2ac84be",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, Encoder_LSTM, Decoder_LSTM):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.Encoder_LSTM = Encoder_LSTM\n",
        "        self.Decoder_LSTM = Decoder_LSTM\n",
        "\n",
        "    def forward(self, source, target, tfr=0.5):\n",
        "        batch_size = source.shape[1]\n",
        "\n",
        "        target_len = target.shape[0]\n",
        "        target_vocab_size = num_decoder_tokens\n",
        "\n",
        "        outputs = torch.zeros(target_len, batch_size, target_vocab_size)\n",
        "\n",
        "        hidden_state, cell_state = self.Encoder_LSTM(source)\n",
        "\n",
        "        x = target[0]\n",
        "\n",
        "        for i in range(1, target_len):\n",
        "            output, ( hidden_state, cell_state ) = self.Decoder_LSTM(x, (hidden_state, cell_state))\n",
        "            outputs[i] = output\n",
        "            best_guess = output.argmax(1) # 1st dimension is word embedding, 0th dimension is batchsize\n",
        "            x = target[i] if random.random() < tfr else best_guess # Either pass the next word correctly from the dataset or use the earlier predicted word\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "KxU_HH2mf7Qm",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c324a3bc939ea45333ebc3d6435cbf34",
          "grade": false,
          "grade_id": "cell-61d8cb7f520b0326",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "\n",
        "learning_rate = 0.001\n",
        "step = 0\n",
        "\n",
        "model = Seq2Seq(encoder, decoder)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "xu-3m5qg0-G1",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "07abc23b4cedabba832b7e15d98d3fef",
          "grade": false,
          "grade_id": "cell-cdd4235d80801b39",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Task 2\n",
        "<b><div style=\"text-align: right\">[POINTS: 3]</div></b>\n",
        "Increase the number of epochs and train the model to obtain a good accuracy score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "cymSsIYQw6Me",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "38a67eb038486a9db3fc03603d8b6ed6",
          "grade": false,
          "grade_id": "cell-d5ca1a01a0838cda",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Some model hyperparameters\n",
        "train_samples = len(X_train)\n",
        "val_samples = len(X_test)\n",
        "batch_size = 256\n",
        "num_epochs = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ZWX1460-zVv6",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1506343e4b40cdd6ca2faf2b9c5c3923",
          "grade": false,
          "grade_id": "cell-9fdc16b573193e9a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc551efd-04e3-4362-a46a-ab5f5c74828f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 1 / 2\n",
            "Iterations / loss -  0 / 9.18850326538086\n",
            "\n",
            "Iterations / loss -  1 / 9.164229393005371\n",
            "\n",
            "Iterations / loss -  2 / 9.131232261657715\n",
            "\n",
            "Iterations / loss -  3 / 9.108542442321777\n",
            "\n",
            "Iterations / loss -  4 / 9.05274772644043\n",
            "\n",
            "Iterations / loss -  5 / 9.0293607711792\n",
            "\n",
            "Iterations / loss -  6 / 8.981374740600586\n",
            "\n",
            "Iterations / loss -  7 / 8.942726135253906\n",
            "\n",
            "Iterations / loss -  8 / 8.823500633239746\n",
            "\n",
            "Iterations / loss -  9 / 8.832266807556152\n",
            "\n",
            "Iterations / loss -  10 / 8.81560230255127\n",
            "\n",
            "Iterations / loss -  11 / 8.806292533874512\n",
            "\n",
            "Iterations / loss -  12 / 8.62870979309082\n",
            "\n",
            "Iterations / loss -  13 / 8.480350494384766\n",
            "\n",
            "Iterations / loss -  14 / 8.400856018066406\n",
            "\n",
            "Iterations / loss -  15 / 8.307788848876953\n",
            "\n",
            "Iterations / loss -  16 / 8.19774055480957\n",
            "\n",
            "Iterations / loss -  17 / 8.091117858886719\n",
            "\n",
            "Iterations / loss -  18 / 7.981252670288086\n",
            "\n",
            "Iterations / loss -  19 / 7.849562644958496\n",
            "\n",
            "Iterations / loss -  20 / 7.725975036621094\n",
            "\n",
            "Iterations / loss -  21 / 7.59799337387085\n",
            "\n",
            "Iterations / loss -  22 / 7.456447601318359\n",
            "\n",
            "Iterations / loss -  23 / 7.308018684387207\n",
            "\n",
            "Iterations / loss -  24 / 7.162673473358154\n",
            "\n",
            "Iterations / loss -  25 / 7.022425174713135\n",
            "\n",
            "Iterations / loss -  26 / 6.8346171379089355\n",
            "\n",
            "Iterations / loss -  27 / 6.682674407958984\n",
            "\n",
            "Iterations / loss -  28 / 6.522868633270264\n",
            "\n",
            "Iterations / loss -  29 / 6.350649356842041\n",
            "\n",
            "Iterations / loss -  30 / 6.193446159362793\n",
            "\n",
            "Iterations / loss -  31 / 6.0056328773498535\n",
            "\n",
            "Iterations / loss -  32 / 5.822490215301514\n",
            "\n",
            "Iterations / loss -  33 / 5.651095390319824\n",
            "\n",
            "Iterations / loss -  34 / 5.476553440093994\n",
            "\n",
            "Iterations / loss -  35 / 5.43494176864624\n",
            "\n",
            "Epoch - 2 / 2\n",
            "Iterations / loss -  0 / 5.1406636238098145\n",
            "\n",
            "Iterations / loss -  1 / 4.966170310974121\n",
            "\n",
            "Iterations / loss -  2 / 4.803866863250732\n",
            "\n",
            "Iterations / loss -  3 / 4.605427265167236\n",
            "\n",
            "Iterations / loss -  4 / 4.443709373474121\n",
            "\n",
            "Iterations / loss -  5 / 4.268316268920898\n",
            "\n",
            "Iterations / loss -  6 / 4.097949504852295\n",
            "\n",
            "Iterations / loss -  7 / 3.9312195777893066\n",
            "\n",
            "Iterations / loss -  8 / 3.7755067348480225\n",
            "\n",
            "Iterations / loss -  9 / 3.6077988147735596\n",
            "\n",
            "Iterations / loss -  10 / 3.431236982345581\n",
            "\n",
            "Iterations / loss -  11 / 3.268270254135132\n",
            "\n",
            "Iterations / loss -  12 / 3.1136934757232666\n",
            "\n",
            "Iterations / loss -  13 / 2.956752061843872\n",
            "\n",
            "Iterations / loss -  14 / 2.797090530395508\n",
            "\n",
            "Iterations / loss -  15 / 2.657372236251831\n",
            "\n",
            "Iterations / loss -  16 / 2.4960172176361084\n",
            "\n",
            "Iterations / loss -  17 / 2.353459358215332\n",
            "\n",
            "Iterations / loss -  18 / 2.2068474292755127\n",
            "\n",
            "Iterations / loss -  19 / 2.073802947998047\n",
            "\n",
            "Iterations / loss -  20 / 1.941749095916748\n",
            "\n",
            "Iterations / loss -  21 / 1.8163827657699585\n",
            "\n",
            "Iterations / loss -  22 / 1.6903612613677979\n",
            "\n",
            "Iterations / loss -  23 / 1.5894311666488647\n",
            "\n",
            "Iterations / loss -  24 / 1.4657893180847168\n",
            "\n",
            "Iterations / loss -  25 / 1.3844189643859863\n",
            "\n",
            "Iterations / loss -  26 / 1.281660556793213\n",
            "\n",
            "Iterations / loss -  27 / 1.1805006265640259\n",
            "\n",
            "Iterations / loss -  28 / 1.0882197618484497\n",
            "\n",
            "Iterations / loss -  29 / 1.0106889009475708\n",
            "\n",
            "Iterations / loss -  30 / 0.9537138342857361\n",
            "\n",
            "Iterations / loss -  31 / 0.8724702596664429\n",
            "\n",
            "Iterations / loss -  32 / 0.8047181367874146\n",
            "\n",
            "Iterations / loss -  33 / 0.7438452243804932\n",
            "\n",
            "Iterations / loss -  34 / 0.6930081248283386\n",
            "\n",
            "Iterations / loss -  35 / 1.006272315979004\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Training the model\n",
        "epoch_loss = 0.0\n",
        "best_loss = 999999\n",
        "losses = []\n",
        "best_epoch = -1\n",
        "ts1  = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss_list = []\n",
        "    print(\"Epoch - {} / {}\".format(epoch+1, num_epochs))\n",
        "    \n",
        "\n",
        "    model.train(True)\n",
        "    for batch_idx, ( input_data, target_data ) in enumerate(generate_batch(batch_size=batch_size)):\n",
        "        input_data_enc = torch.tensor(input_data[0]).long()\n",
        "        input_data_dec = torch.tensor(input_data[1]).long()\n",
        "        target = torch.tensor(target_data.argmax(2)).long()\n",
        "        \n",
        "        # Pass the input and target for model's forward method\n",
        "        output = model(input_data_enc, target)\n",
        "        output = output[1:].reshape(-1, output.shape[2])\n",
        "        target = target[1:].reshape(-1)\n",
        "\n",
        "        # Clear the accumulating gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Calculate the loss value for every epoch\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Calculate the gradients for weights & biases using back-propagation\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the weights values using the gradients we calculated using bp \n",
        "        optimizer.step()\n",
        "        step += 1\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        epoch_loss_list.append(loss.item())\n",
        "\n",
        "        if epoch_loss < best_loss:\n",
        "            best_loss = epoch_loss\n",
        "            best_epoch = epoch\n",
        "        if ((epoch - best_epoch) >= 10):\n",
        "            print(\"no improvement in 10 epochs, break\")\n",
        "            break\n",
        "        print(\"Iterations / loss -  {} / {}\".format(batch_idx,loss.item()))\n",
        "        print()\n",
        "    losses.append(np.mean(epoch_loss_list))\n",
        "\n",
        "torch.save({\n",
        "          'model_state_dict': model.state_dict(),\n",
        "          'loss': losses\n",
        "          },\"lstm_seq2seq\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "deletable": false,
        "id": "K1kgspYr0-G1",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a606c7517aefd327f82ecdc8c1e0c180",
          "grade": false,
          "grade_id": "cell-404e9c0d68a46c7c",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "tags": [
          "Ex-4-Task-2"
        ]
      },
      "outputs": [],
      "source": [
        "### Ex-4-Task-2\n",
        "loss = None\n",
        "\n",
        "# Model Loss\n",
        "# Store the model's loss from trained above\n",
        "\n",
        "# Exercise 4 | Task 2\n",
        "### BEGIN SOLUTION\n",
        "# your code here\n",
        "loss = losses\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "AUJwO-z2LORt",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fe4b6e1a7da659d7d7bb61358f49fe84",
          "grade": false,
          "grade_id": "cell-cd972e8c828f74d6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c3b0b07-8668-4530-c636-1863eb747538"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7.751729461881849, 2.5144000318315296]"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ],
      "source": [
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "rcMS1UgA0-G1",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7f502d775a57040c58d4ee2ec8f3023d",
          "grade": true,
          "grade_id": "cell-2c02ab4a9929d13a",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false
        },
        "tags": [
          "Ex-4-Task-2"
        ]
      },
      "outputs": [],
      "source": [
        "#INTENTIONALLY LEFT BLANK\n",
        "assert loss is not None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "h50t4Y7f0-G1",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d560f9d70599bdd447567969c6bb2f08",
          "grade": false,
          "grade_id": "cell-8989e398a4400b6e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Now, after we performed some preprocessing and model training steps, then we will start working on the model inferencing. We will see how well the model predicts the results. Also, we will discover what can be the possible solution to this problem.\n",
        "\n",
        "If we look at the model training results, we can see that the model is not performing really well. This may be because the LSTM network we are using is not able to learn the appropriate feature inputs. The no. of tokens is also pretty large which is giving the model a hard time to learn the input feature itself. So, the possible solution to these problems could be the `Attention Mechanisms`. We have not used attention mechanism, however if we use attention mechanism the result will surely turn out better.\n",
        "\n",
        "Moreover, we can validate the performance of the model by also inferencing on the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "vm-p0L85w6Mi",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8c8a39c7744b369949a86787e8834f7f",
          "grade": false,
          "grade_id": "cell-c942df3936e27c26",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "###  Decode Sample Sequences\n",
        "\n",
        "Following is the code to decode the input sequence to the machine translation network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "SEf9I1brw6Mi",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5a0b45c69b73e5f81bf61c8626dadf94",
          "grade": false,
          "grade_id": "cell-5ed91b4ae4003424",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "model = Seq2Seq(Encoder(num_encoder_tokens, latent_dim, latent_dim), Decoder(num_decoder_tokens, latent_dim, latent_dim, num_decoder_tokens))\n",
        "\n",
        "\n",
        "checkpoint = torch.load(\"lstm_seq2seq\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "def decode_sequence(sentence, max_length=50):\n",
        "    model.eval()\n",
        "    # lower, removing punctuations, \n",
        "    tokens =  (''.join(char for char in re.sub(\" +\", \" \", re.sub(\"'\", '', sentence).lower()) if char not in sets_of_punctuations)).split()\n",
        "\n",
        "    text_to_indices = [ input_token_index[token] for token in tokens]\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1)\n",
        "\n",
        "    # Build encoder hidden, cell state\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.Encoder_LSTM(sentence_tensor)\n",
        "\n",
        "    outputs = [target_token_index[\"<START>\"]]\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        previous_word = torch.LongTensor([outputs[-1]])\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, ( hidden, cell ) = model.Decoder_LSTM(previous_word, (hidden, cell))\n",
        "            best_guess = output.argmax(1).item()\n",
        "\n",
        "        outputs.append(best_guess)\n",
        "\n",
        "        # Model predicts it's the end of the sentence\n",
        "        if best_guess == \"<END>\":\n",
        "            break\n",
        "\n",
        "    translated_sentence = [reverse_target_char_index.get(idx, '<PAD>') for idx in outputs]\n",
        "    return translated_sentence[1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "nlUCxJsnw6Mj",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "763c22c34ded6325c5ad21a2a9355592",
          "grade": false,
          "grade_id": "cell-c83a2b40557db068",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Evaluation on Train Dataset\n",
        "\n",
        "Generating the sample to check some of the results predicted by the machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "C_pmnLSGw6Mk",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "62ea65b73b7feb701332ebb26bccf2e2",
          "grade": false,
          "grade_id": "cell-5ecd5fc414a45548",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c999db6-dc29-49d9-a12d-de12909d73ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input English sentence: why isnt that good\n",
            "Actual Chinese Translation: <START> 那為甚麼不好？ <END>\n",
            "Predicted Chinese Translation: ['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
          ]
        }
      ],
      "source": [
        "k=0\n",
        "decoded_sentence = decode_sequence(X_train[k:k+1].values[0])\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Chinese Translation:', y_train[k:k+1].values[0])\n",
        "print('Predicted Chinese Translation:', decoded_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "t9-tBDjSw6Mk",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2cb0841aa20be247dc2cfa65c9ff8f81",
          "grade": false,
          "grade_id": "cell-ed8c1f20e44cf9ea",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33dd6d08-6de1-4c98-b770-e72d1d14c80a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input English sentence: do you believe what he said\n",
            "Actual Chinese Translation: <START> 你相信他說的話嗎？ <END>\n",
            "Predicted Chinese Translation: ['<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
          ]
        }
      ],
      "source": [
        "k+=1\n",
        "decoded_sentence = decode_sequence(X_train[k:k+1].values[0])\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Chinese Translation:', y_train[k:k+1].values[0])\n",
        "print('Predicted Chinese Translation:', decoded_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "3TZxb_9Yw6Ml",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b5fa51f0d95647f9eabb3536d3f3ffc8",
          "grade": false,
          "grade_id": "cell-415bd9a5589e425e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50682662-8cf2-4ed7-bc26-07e31c8c240d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input English sentence: tom will follow my advice\n",
            "Actual Chinese Translation: <START> 汤姆会听从我的建议。 <END>\n",
            "Predicted Chinese Translation: ['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
          ]
        }
      ],
      "source": [
        "k+=1\n",
        "decoded_sentence = decode_sequence(X_train[k:k+1].values[0])\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Chinese Translation:', y_train[k:k+1].values[0])\n",
        "print('Predicted Chinese Translation:', decoded_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "udM3JsI9w6Ml",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1e0a03d70e00916d5e4b79b1f091cb4e",
          "grade": false,
          "grade_id": "cell-7fcb2d3381bba963",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24276dc4-3fce-48aa-8927-1ed8a7fa87fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input English sentence: i lent my friend some money\n",
            "Actual Chinese Translation: <START> 我借给了朋友一些钱。 <END>\n",
            "Predicted Chinese Translation: ['<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
          ]
        }
      ],
      "source": [
        "k+=1\n",
        "decoded_sentence = decode_sequence(X_train[k:k+1].values[0])\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Chinese Translation:', y_train[k:k+1].values[0])\n",
        "print('Predicted Chinese Translation:', decoded_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "dCL7Qdt5w6Mm",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f36cbe941bac7f99dbc50e5e80d1c331",
          "grade": false,
          "grade_id": "cell-5e36305a19daeb11",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9745b18-47e1-45de-d5aa-61c19759aba3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input English sentence: im reading\n",
            "Actual Chinese Translation: <START> 我在读书。 <END>\n",
            "Predicted Chinese Translation: ['我们是为了死亡而诞生的。', '您经常去吗？', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
          ]
        }
      ],
      "source": [
        "k+=1\n",
        "decoded_sentence = decode_sequence(X_train[k:k+1].values[0])\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Chinese Translation:', y_train[k:k+1].values[0])\n",
        "print('Predicted Chinese Translation:', decoded_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "eGmUTVPS0-G3",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "4482e01ff125db80d9d6e06049834443",
          "grade": false,
          "grade_id": "cell-b60c247b0c3f991f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "CONGRATULATIONS!!! on completing the Assignment."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}